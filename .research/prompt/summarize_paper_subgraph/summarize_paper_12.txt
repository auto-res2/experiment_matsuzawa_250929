
Input:

You are an expert research assistant responsible for summarizing a research paper that will serve as the foundation (Research A) for further exploration and integration.

Your task is to generate a structured summary of the given research paper with a focus on:
- **Technical Contributions**: Identify the main research problem and key findings.
- **Methodology**: Describe the techniques, models, or algorithms used.
- **Experimental Setup**: Outline the datasets, benchmarks, and validation methods.
- **Limitations**: Highlight any weaknesses, constraints, or assumptions.
- **Future Research Directions**: Suggest possible extensions or new areas for research.

Below is the full text of the research paper:

```
Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement Samuel Daulton Facebook, University of Oxford sdaulton@fb.com Maximilian Balandat Facebook balandat@fb.com Eytan Bakshy Facebook ebakshy@fb.com Abstract Optimizing multiple competing black-box objectives is a challenging problem in many ﬁelds, including science, engineering, and machine learning. Multi-objective Bayesian optimization (MOBO) is a sample-efﬁcient approach for identifying the optimal trade-offs between the objectives. However, many existing methods perform poorly when the observations are corrupted by noise. We propose a novel acquisition function, NEHVI , that overcomes this important practical limitation by applying a Bayesian treatment to the popular expected hypervolume improvement (EHVI ) criterion and integrating over this uncertainty in the Pareto frontier. We argue that, even in the noiseless setting, generating multiple candidates in parallel is an incarnation of EHVI with uncertainty in the Pareto frontier and therefore can be addressed using the same underlying technique. Through this lens, we derive a natural parallel variant, qNEHVI , that reduces computational complexity of parallel EHVI from exponential to polynomial with respect to the batch size. qNEHVI is one-step Bayes-optimal for hypervolume maximization in both noisy and noiseless environments, and we show that it can be optimized effectively with gradient-based methods via sample average approximation. Empirically, we demonstrate not only that qNEHVI is substantially more robust to observation noise than existing MOBO approaches, but also that it achieves state-of-the-art optimization performance and competitive wall-times in large-batch environments. 1 Introduction Black-box optimization problems that involve multiple competing noisy objectives are ubiquitous in science and engineering. For example, a real-time communications service may be interested in tuning the parameters of a control policy to adapt video quality in real time in order to maximize video quality and minimize latency [ 10, 17]. In robotics, scientists may seek to design hardware components that maximize locomotive speed and minimize energy expended [8, 38]. In agriculture, development agencies may seek to balance crop yield and environmental impact [ 28]. For such multi-objective optimization (MOO) problems, there typically is no single solution that is best with respect to all objectives. Rather, the goal is to identify the Pareto frontier: a set of optimal trade-offs such that improving one objective means deteriorating another. In many cases, the objectives are expensive to evaluate. For instance, randomized trials used in agriculture and the internet industry may take weeks or months to conduct and incur opportunity costs, and manufacturing and testing hardware is both costly and time-consuming. Therefore, it is imperative to be able to identify good trade-offs with as few objective evaluations as possible. Bayesian optimization (BO), a method for efﬁcient global black-box optimization, is often used to tackle such problems. BO employs a probabilistic surrogate model in conjunction with an acquisition function to navigate the trade-off between exploration (evaluating designs with high uncertainty) and exploitation (evaluating designs that are believed to be optimal). Although a signiﬁcant number of works have explored multi-objective Bayesian optimization (MOBO), most available methods 35th Conference on Neural Information Processing Systems (NeurIPS 2021) arXiv:2105.08195v2  [cs.LG]  26 Oct 2021[3, 39, 51, 60] do not take into account the fact that, in practice, observations are often subject to noise. For example, results of an A/B test are highly variable due to heterogeneity in the underlying user population and other factors. Agricultural trials are affected by the stochastic nature of plant growth and environmental factors such as soil composition or wind currents. In robotics, devices are subject to manufacturing tolerances, and observations of quantities such as locomotive speed and efﬁciency may be corrupted by measurement error from noisy sensors and environmental factors such as temperature or surface friction. While previous work has shown that a principled treatment of noisy observations can signiﬁcantly improve optimization performance in the single-objective case [24, 37], this issue is understudied in the multi-objective setting. Furthermore, many applications in which evaluations take a long time require evaluating large batches of candidates in parallel in order to achieve reasonable throughput. For example, when ﬁrms optimize systems via A/B tests, it may take several weeks to test any particular conﬁguration. Because of this, large batches of candidate policies are tested simultaneously [36]. In biochemistry and materials design, dozens of tests can be conducted parallel on a single microplate [63]. Even in sophisticated high throughput chemistry settings, these batches may take several hours or days to set up and evaluate [ 42]. Most existing MOBO methods, however, are either designed for purely sequential optimization [3, 51] or do not scale well to large batch sizes [11]. Contributions: In this work, we propose a novel MOBO algorithm, based on expected hypervolume improvement (EHVI), that scales to highly parallel evaluations of noisy objectives. Our approach is made possible by a general-purpose, differentiable, cached box decomposition (CBD) implementation that dramatically speeds up critical computations needed to account for uncertainty introduced by noisy observations and generate new candidate points for highly parallel batch or asynchronous evaluation. In particular, our CBD-based approach solves the fundamental problem of scaling parallel EHVI-based methods to large batch sizes, reducing time and space complexity from exponential to polynomial. Our proposed algorithm, noisy expected hypervolume improvement (NEHVI ), is the one- step Bayes-optimal policy for hypervolume improvement and provides state-of-the-art performance across a variety of benchmarks. To our knowledge, our work provides the most extensive evaluation of noisy parallel MOBO to date. A high-quality implementation of qNEHVI , as well as many of the baselines considered here, will be made available as open-source software upon publication. 2 Preliminaries Our goal is to ﬁnd the set of optimal designs xover a bounded set X⊂ Rd that maximize one or more objectives f(x) ∈RM, with no known analytical expression nor gradient information of f. Multi-Objective Optimization (MOO) aims to identify the set of Pareto optimal objective trade- offs. We say a solution f(x) = [ f(1)(x),...,f (M)(x) ] dominates another solution f(x) ≻f(x′) if f(m)(x) ≥f(m)(x′) for m= 1,...,M and ∃m∈{1,...,M }s.t. f(m)(x) >f (m)(x′). We deﬁne the Pareto frontier as P∗= {f(x) : x∈X, ∄ x′∈X s.t.f(x′) ≻f(x)}, and denote the set of Pareto optimal designs as X∗= {x: f(x) ∈P∗}. Since the Pareto frontier (PF) is often an inﬁnite set of points, MOO algorithms usually aim to identify a ﬁnite approximate PF P. A natural measure of the quality of a PF is the hypervolume of the region of objective space that is dominated by the PF and bounded from below by a reference point. Provided with the approximate PF, the decision-maker can select a particular Pareto optimal trade-off according to their preferences. Bayesian Optimization (BO) is a sample-efﬁcient optimization method that leverages a probabilistic surrogate model to make principled decisions to balance exploration and exploitation [ 19, 50]. Typically, the surrogate is a Gaussian Process (GP), a ﬂexible, non-parametric model known for its well-calibrated predictive uncertainty [47]. To decide which points to evaluate next, BO employs an acquisition function α(·) that speciﬁes the value of evaluating a set of new points xbased on the surrogate’s predictive distribution at . While evaluating the true black-box function f is time- consuming or costly, evaluating the surrogate is cheap and relatively fast; therefore, numerical optimization can be used to ﬁnd the maximizer of the acquisition function x∗= arg maxx∈Xα(x) to evaluate next on the black-box function. BO sequentially selects new points to evaluate and updates the model to incorporate the new observations. Evolutionary algorithms (EAs) such as NSGA-II [12] are a popular choice for solving MOO problems (see Zitzler et al. [67] for a review of various other approaches). However, EAs generally suffer from high sample complexity, rendering them infeasible for optimizing expensive-to-evaluate black-box 2functions. Multi-objective Bayesian optimization (MOBO), which combines a Bayesian surrogate with an acquisition function designed for MOO, provides a much more sample-efﬁcient alternative. 3 Related Work Methods based on hypervolume improvement (HVI) seek to expand the volume of the objective space dominated by the Pareto frontier. Expected hypervolume improvement ( EHVI ) [16] is a natural extension of the popular expected improvement (EI) [29] acquisition function to the MOO setting. Recent work has led to efﬁcient computational paradigms using box decomposition algorithms [59] and practical enhancements such as support for parallel candidate generation and gradient-based acquisition optimization [11, 58]. However, EHVI still suffers from some limitations, including (i) the assumption that observations are noise-free, and (ii) the exponential scaling of its batch variant, qEHVI , in the batch size q, which precludes large-batch optimization. DGEMO [ 39] is a recent method for parallel MOBO that greedily maximizes HVI while balancing the diversity of the design points being sampled. Although DGEMO scales well to large batch sizes, it does not account for noisy observations. TSEMO [5] is a Thompson sampling (TS) heuristic that can acquire batches of points by optimizing a random fourier feature (RFF) [ 46] approximation of a GP surrogate using NSGA-II and selecting a subset of points from the EA’s population to sequentially greedily maximize HVI. This heuristic approach for maximizing HVI currently has no theoretical guarantees and relies on zeroth-order optimization methods, which tend to be slower and exhibit worse optimization performance than gradient-based approaches. Entropy-based methods such as PESMO [ 25], MESMO [3], and PFES [ 51] are an alternative to EHVI . Of these three methods, PESMO is the only one that accounts for observation noise. However, PESMO involves intractable entropy computations and therefore relies on complex approximations, as well as challenging and time-consuming numerical optimization procedures [25]. Garrido-Merchán & Hernández-Lobato [21] recently proposed an extension to PESMO that supports parallel candidate generation. However, the authors of this work provide limited evaluation and have not provided code to reproduce their results.1 MOO can also be cast into a single-objective problem by applying a random scalarization of the objectives. ParEGO maximizes the expected improvement using random augmented Chebyshev scalarizations [32]. MOEA/D-EGO [64] extends ParEGO to the batch setting using multiple random scalarizations and the genetic algorithm MOEA/D [65] to optimize these scalarizations in parallel. Recently, qParEGO, another batch variant of ParEGO was proposed that uses compositional Monte Carlo objectives and sequential greedy candidate selection [11]. Additionally, the authors proposed a noisy variant, qNParEGO, but the empirical evaluation of that variant was limited. TS-TCH [45] combines random Chebyshev scalarizations with Thompson sampling [54], which is naturally robust to noise when the objective is scalarized. Golovin & Zhang [23] propose to use a hypervolume scalarization with the property that the expected value of the scalarization over a speciﬁc distribution of weights is equivalent to the hypervolume indicator. The authors propose a upper conﬁdence bound algorithm using randomly sampled weights, but provide a very limited empirical evaluation. Many prior attempts by the simulation community to handle MOO with noisy observations found that accounting for the noise did not improve optimization performance: Horn et al. [26] suggest that the best approach is to ignore noise, and Koch et al. [33] concluded that further research was needed to determine if modeling techniques such as re-interpolation could improve BO performance with noisy observations. In contrast, we ﬁnd that accounting for noise does substantially improve performance in noisy settings. Lastly, previous works have considered methods for quantifying and monitoring uncertainty in the Pareto frontiers during the optimization [ 4, 7]. In contrast, we provide a solution to performing MOBO in noisy settings, rather than purely reasoning about the uncertainty in the Pareto frontier. 4 Background on Expected Hypervolume Improvement In this section, we review hypervolume, hypervolume improvement, and expected hypervolume improvement as well as efﬁcient methods for computing these metrics using box decompositions. 1We contacted the authors twice asking for code to reproduce their results, but they graciously declined. 3Deﬁnition 1. The hypervolume indicator ( HV) of a ﬁnite approximate Pareto frontier Pis the M-dimensional Lebesgue measure λM of the space dominated by Pand bounded from below by a reference point. r∈RM: HV(P|r) = λM (⋃ v∈P[r,v] ) , where [r,v] denotes the hyper-rectangle bounded by vertices rand v. As in previous work, we assume that the reference point ris known and speciﬁed by the decision maker [58]. Deﬁnition 2. The hypervolume improvement (HVI) of a set of pointsP′w.r.t. an existing approximate Pareto frontierPand reference point ris deﬁned as2 HVI (P′|P,r) = HV(P∪P ′|r) −HV(P|r). Computing HV requires calculating the volume of a typically non-rectangular polytope and is known to have time complexity that is super-polynomial in the number of objectives [ 59]. An efﬁcient approach for computing HV is to (i) decompose the region that is dominated by the Pareto frontier Pand bounded from below by the reference point r into disjoint axis-aligned hyperrectangles [34], (ii) compute the volume of each hyperrectangle in the decomposition, and (iii) sum over all hyperrectangles. So-called box decomposition algorithms have also been applied to partition the region that is not dominated by the Pareto frontier P, which can be used to compute the HVI from a set of new points [15, 59]. See Appendix B for further details. Expected Hypervolume Improvement: Since function values at unobserved points are unknown in black-box optimization, so is the HVI of an out-of-sample point. However, in BO the probabilistic surrogate model provides a posterior distribution p(f(x)|D) over the function values for each x, which can be used to compute the expected hypervolume improvement (EHVI ) acquisition function: αEHVI (x|P) = E [ HVI(f(x)|P) ] . Although αEHVI can be expressed analytically when (i) the objectives are assumed to be conditionally independent given xand (ii) the candidates are generated and evaluated sequentially [58], Monte Carlo (MC) integration is commonly used since it does not require either assumption [16]. The more general parallel variant using MC integration is given by αqEHVI (Xcand|P) ≈ˆαqEHVI (Xcand|P) = 1 N N∑ t=1 HVI ( ˜ft(Xcand)|P), (1) where ˜ft ∼p(f|D) for t = 1 ,...,N and Xcand = {xi}q i=1 [11]. The same box decomposition algorithms used to compute HVI can be used to compute EHVI (either analytic or via MC) using piece-wise integration. EHVI computation is agnostic to the choice of box decomposition algorithm (and can also use approximate methods [ 9]). Similar to EI in the single-objective case, EHVI is a one-step Bayes-optimal algorithm for maximizing hypervolume in the MOO setting under the following assumptions: (i) only a single design will be generated and evaluated, (ii) the observations are noise-free, (iii) the ﬁnal approximate Pareto frontier (and ﬁnal design that will be deployed) will be drawn from the set of observed points [19]. 5 Expected Hypervolume Improvement with Noisy Observations We consider the case that frequently arises in practice where we only receive noisy observations yi = f(xi) + ϵi, ϵi ∼N (0,Σi), where Σi is the noise covariance. In this setting, EHVI is no longer (one-step) Bayes-optimal. This is because we can no longer compute the true Pareto frontier Pn = {f(x) |x∈Xn, ∄ x′∈Xn s.t.f(x′) ≻f(x)}over the previously evaluated points Xn = {xi}n i=1. Simply using the observed Pareto frontier, Yn = {y|y∈Yn, ∄ y′∈Yn s.t.y′≻y,y} where Yn = {yi}n i=1, can have strong detrimental effects on optimization performance. This is illustrated in Figure 1, which shows how EHVI is misled by noisy observations that appear to be Pareto optimal. EHVI proceeds to spend its evaluation budget trying to optimize noise, resulting in a clumped Pareto frontier that lacks diversity. Although the posterior mean could serve as a "plug-in" estimate of the true function values at the observed points and provide some regularization [61], we ﬁnd that this heuristic also leads to clustered Pareto frontiers (EHVI-PM in Fig. 1). Similar patterns emerge with DGEMO (which does not account for noise), and other baselines that utilize the posterior mean rather than the observed values when computing hypervolume improvement (see Appendix H). To our knowledge, all previous work onEHVI assumes that observations are noiseless [16, 58] or imputes the unknown true function values with the posterior mean. 2For brevity we omit the reference point r when referring to HVI. 4-15 -10 -5 0 Objective 1 -6 -5 -4 -3 -2 -1Objective 2  NEHVI EHVI EHVI-PM Ref. Point True PF Figure 1: An illustration of the effect of noisy observations on the true noiseless Pareto frontiers identiﬁed by NEHVI (our pro- posed algorithm), EHVI , and EHVI -PM, which uses the modeled posterior mean as point estimate of the true in-sample function values. All algorithms are tested on a BraninCurrin synthetic prob- lem, where observations are corrupted with zero-mean, additive Gaussian noise with a standard deviation of 5% of the range of respective objective. All methods use sequential (q= 1) optimiza- tion. See Appendix G for details. 5.1 A Bayes-optimal algorithm for hypervolume maximization in noisy environments In contrast with EHVI(-PM), we instead approach the problem of hypervolume maximization under noisy observations from a Bayesian perspective and derive a novel one-step Bayes-optimal expected hypervolume improvement criterion that iterates the expectation over the posterior distribution p(f(Xn)|Dn) of the function values at the previously evaluated points Xn given noisy observa- tions Dn = {xi,yi,(Σi)}n i=1. Our acquisition function, noisy expected hypervolume improvement (NEHVI), is deﬁned as αNEHVI (x) = ∫ αEHVI (x|Pn)p(f|Dn)df (2) where Pn denotes the Pareto frontier over f(Xn). By integrating over the uncertainty in the function values at the observed points, NEHVI retains one-step Bayes-optimality in noisy environments (in noiseless environments,NEHVI is equivalent to EHVI ). Empirically, Figure 1 shows that NEHVI is robust to noise and identiﬁes a well-distributed Pareto frontier with no signs of clumping, even under very noisy observations.3 The integral in (2) is analytically intractable, but can easily be approximated using MC integration. Let ˜ft ∼p(f|Dn) for t = 1 ,...N be samples from the posterior, and let Pt = {˜ft(x) |x ∈ Xn, ˜ft(x) ≻ ˜ft(x′) ∀x′∈Xn}be the Pareto frontier over the previously evaluated points under the sampled function ˜ft. Then, αNEHVI (x) ≈ 1 N ∑ N t=1 αEHVI (x|Pt). Using MC integration, we can compute the inner expectation in αEHVI simultaneously using samples from the joint posterior ˜ft(Xn,x) ∼p(f(Xn,x)|Dn) over xand Xn: ˆαNEHVI (x) = 1 N N∑ t=1 HVI ( ˜ft(x)|Pt). (3) See Appendix B for details on computing (3) using box decompositions. Note that this “full-MC” variant of NEHVI does not require objectives to be modeled independently, and supports multi-task covariance functions across correlated objectives. 5.2 Parallel Noisy Expected Hypervolume Improvement Generating and evaluating batches of candidates is imperative to achieving adequate throughput in many real-world scenarios. q NEHVI can naturally be extended to the parallel (asynchronous or batch) setting by evaluating HVI with respect to a batch of qpoints Xcand = {xi}q i=1 αqNEHVI (Xcand) = ∫ αqEHVI (Xcand|Pn)p(f|Dn)df≈ˆαqNEHVI (Xcand) = 1 N N∑ t=1 HVI ( ˜ft(Xcand)|Pt) (4) Since optimizing q candidates jointly is a difﬁcult numerical optimization problem over a qd- dimensional domain, we use a sequential greedy approximation in the parallel setting and solve a sequence of q simpler optimization problems with ddimensions, which been shown empirically to improve optimization performance [57]. While selecting candidates according to a “sequential greedy” policy does not guarantee that the selected batch of candidates is a maximizer of theαqNEHVI , the submodularity of αqNEHVI allows us to bound the regret of this approximation to be no more than 1 eα∗ qNEHVI , where α∗ qNEHVI = maxXcand∈XαqNEHVI (Xcand) (see Appendix F). 3This noise level is 5x greater than the ones considered by previous works that evaluate noisy MOBO [25]. 56 Efﬁcient Evaluation with Cached Box Decompositions Although ˆαNEHVI (x) in (3) has a concise mathematical form, computing it requires determining the Pareto frontier Pt under each sample ˜ft for t= 1,...,N and then partitioning the region that is not dominated by Pt into disjoint hyperrectangles {Skt}Kt kt=1. Optimizing the unbiased MC estimator of αNEHVI would require re-sampling {˜ft}N t=1 at each evaluation of αNEHVI . However, computing the Pareto frontier and performing a box decomposition under each of the N samples during every evaluation of αNEHVI in the inner optimization loop ( x∗ = arg maxx αNEHVI (x|Dn)) would be prohibitively expensive. This is because box decomposition algorithms have super-polynomial time complexity in the number of objectives [59]. We instead propose an efﬁcient alternative computational technique for repeated evaluations of EHVI with uncertain Pareto frontiers. Cached Box Decompositions: For repeated evaluations of the integral in (2), we use a set of ﬁxed samples {˜ft(Xn)}N t=1, which allows us to compute the Pareto frontiers and box decompositions once, and cache them for the entirety of the acquisition function optimization, thereby making those two computationally intensive operations a one-time cost per BO iteration.4 We refer to this approach as using cached box decompositions (CBD ). The method of optimizing over ﬁxed random samples is known as sample average approximation (SAA) [2]. Conditional Posterior Sampling: Under the CBD formulation, computing ˆαNEHVI (x) with joint samples from ˜ft(Xn,x) ∼p(f(Xn,x)|Dn) requires sampling from the conditional distributions ˜ft(x) ∼p ( f(x)|f(Xn) = ˜ft(Xn),Dn ) , (5) where t = 1,...,N and {˜ft(Xn)}N t=1 are the realized samples at the previously evaluated points. For multivariate Gaussian posteriors (as is the case with GP surrogates), we can sample from p(f(Xn)|Dn) via the reparameterization trick [ 30] by evaluating ˜ft(x) = µn + LT nζn,t,where ζn,t ∼N(0,InM), µn ∈RnM is the posterior mean, and Ln ∈RnM×nM is a lower triangular root decomposition of the posterior covariance matrix, typically a Cholesky decomposition. Given Ln, we can obtain a root decomposition L′ n of the covariance matrix of the joint posterior p(f(Xn,x)|Dn) by performing efﬁcient low-rank updates [44]. Given L′ n and the posterior mean of p(f(Xn,x)|Dn), we can sample from (5) via the reparameterization trick by augmenting the existing base samples ζn,t with M new base samples for the new point. 6.1 Efﬁcient Sequential Greedy Batch Selection using CBD The CBD technique addresses the general problem of inefﬁcient repeated evaluations of EHVI with uncertain Pareto frontiers. In this section, we show that sequential greedy batch selection (with both qEHVI and qNEHVI) is an incarnation of EHVI with uncertain Pareto frontiers. The original formulation of parallel EHVI in Daulton et al.[11] uses the inclusion-exclusion principle (IEP ), which involves computing the volume jointly dominated by each of the 2q −1 nonempty subsets of points in Xcand. However, using large batch sizes is not computationally feasible under this formulation because time and space complexity are exponential in qand multiplicative in the number of hyperrectangles in the box decomposition [11] (see Appendix D for a complexity analysis). Although qEHVI is optimized using sequential greedy batch selection, the IEP is used over all candidates x1,..., xi when selecting candidate i. Although the IEP could similarly be used to compute qNEHVI , we instead leverage CBD, which yields a sequential greedy approximation of the joint (noisy) EHVI that is mathematically equivalent to the IEP formulation, but signiﬁcantly reduces computational overhead. That is, the IEP and CBD approaches produce exactly the same acquisition value for a given set of points Xcand, but the IEP and the CBD approaches have exponential and polynomial time complexities in q, respectively. When selecting xi for i ∈{2,...,q }, all xj for which j < ihave already been selected and are therefore held constant. Thus, we can decompose qNEHVI into the qNEHVI from the previously selected candidates x1,..., xi−1 and NEHVI from xi given the previously selected candidates 4For greater efﬁciency, we may also prune Xn to remove points that are dominated with high probability, which we estimate via MC. 60 20 40 60 80 100 q 0 100 200 300Acquisition Optimization Time (s) CBD (CPU) CBD (GPU) IEP (CPU) IEP (GPU) OOM Figure 2: Acquisition optimization wall time under a sequential greedy approximation using L-BFGS-B. CBD enables scaling to much larger batch sizes qthan using the IEP and avoids running out-of-memory (OOM) on a GPU. Independent GPs are used for each outcome. The Pareto frontier of of the 2-objective, 6- dimensional DTLZ2 problem [ 13] is initialized with 20 points. Wall times were measured on a Tesla V100 SXM2 GPU (16GB RAM) and a 2x Intel Xeon 6138 CPU @ 2GHz (251GB RAM). See Appendix H.2 for results with more objectives. ˆαqNEHVI ({xj}i j=1) = 1 N N∑ t=1 HVI ( {˜ft(xj)}i−1 j=1}|Pt ) + 1 N N∑ t=1 HVI ( ˜ft(xi) |Pt∪{˜ft(xj)}i−1 j=1} ) (6) Note that the ﬁrst term on the right hand side is constant, since {xj}i−1 j=1 and {˜ft(xj)}i−1 j=1 are ﬁxed for all t = 1 ,...,N . The second term is ˆαNEHVI (xi), where the NEHVI is taken with respect to the Pareto frontier across f(Xn,x1,..., xi−1) and computed using the ﬁxed samples {˜ft(Xn,x1,...xi−1)}N t=1. To compute the second term when selecting candidate xi, the N Pareto frontiers and CBD s are updated to include {˜ft(Xn,x1,...xi−1)}N t=1. As in the sequential q = 1 setting, the box decompositions are only computed and cached while selecting each candidate point. See Appendix C.2 for a derivation of (6). Although we have focused on qNEHVI in the above, the CBD formulation for qEHVI is obtained by simply replacing Pt with the Pareto frontier over the observed values Yn. Despite computing Nbox decompositions when selecting each candidatexifor i= 2,...,q , the CBD approach reduces the time and space complexity from exponential (under the IEP ) to polynomial in q(see Appendix D for details on time and space complexity). Figure 2 shows the total acquisition optimization time (including box decompositions) for various batch sizes and demonstrates that using CBD allows to scale to batch sizes that are completely infeasible when using IEP. 7 Optimizing NEHVI Differentiability: Importantly, ˆαNEHVI (x) is differentiable w.r.t. x. Although determining the Pareto frontier and computing the box decompositions are non-differentiable operations, these operations do not involve x, even when re-sampling from the joint posterior p(f(Xn,x)|Dn). Exact sample-path gradients of ∇x ˆαNEHVI (x) can easily be computed using auto-differentiation in modern computational frameworks. This enables efﬁcient gradient-based optimization of qNEHVI. 5 SAA Convergence Results: In addition to approximating the outer expectation over f(Xn) with ﬁxed posterior samples, we can similarly ﬁx the base samples used for the new candidate point x. This approach yields a deterministic acquisition function, which enables using (quasi-) higher-order optimization methods to obtain fast convergence rates for acquisition optimization [2]. Importantly, we prove that the theoretical convergence guarantees on acquisition optimization under the SAA approach proposed by Balandat et al. [2] also hold for NEHVI. Theorem 1. Suppose Xis compact and fhas a multi-output GP prior with continuously differen- tiable mean and covariance functions. Let Xn = {xi}n i=1 denote the previously evaluated points and {ζ}N t=1 be base samples ζ ∼N (0,I(n+1)M). Let ˆαNEHVI denote the deterministic acquisi- tion function computed using {ζ}N t=1 as ˆαN NEHVI and deﬁne S∗ := arg maxx∈XαNEHVI (x) to be the set of maximizers of αNEHVI (x) over X. Suppose ˆx∗ N ∈arg maxx∈X ˆαN NEHVI (x). Then (1) ˆαN NEHVI (ˆx∗ N) →αNEHVI (x∗ N) almost surely, and (2) dist(ˆx∗ N,S∗) →0, where dist(ˆx∗ N,S∗) := infx∈S∗||ˆx∗ N −x||is the Euclidean distance between ˆx∗ N and the set S∗. Theorem 1 also holds in the parallel setting, so qNEHVI enjoys the same convergence guarantees as NEHVI on acquisition optimization under the SAA. See Appendix E for further details and proof. 5One can also show that the gradient of the full MC estimator ˆαqNEHVI is an unbiased estimator of the gradient of the true joint noisy expected hypervolume improvement αqNEHVI . However, this result is not necessary for our SAA approach. 78 Approximation of qNEHVI using Approximate GP Sample Paths Although CBD yields polynomial complexity of qNEHVI with respect to q(rather than exponential complexity with the IEP), it still requires computingNbox decompositions and repeatedly evaluating the joint posterior over f(Xn,{xj}i−1 j=1) for selecting each candidate xi for i= 1,...,q . A cheaper alternative is to approximate the integral in (4) using a single approximate GP sample path ˜fi using RFFs when optimizing candidate xi. A single-sample approximation of qNEHVI, which we refer to as qNEHVI-1 , can be computed by using ˜fi as the sampled GP in (6). Since the RFF is a deterministic model, it is much less computationally expensive to evaluate than the GP posterior on out-of-sample points, and exact gradients of qNEHVI-1 with respect to current candidate xi can be computed and used for efﬁcient multi-start optimization of qNEHVI-1 using second-order gradient methods. qNEHVI-1 requires CBD for efﬁcient sequential greedy batch selection and gradient-based optimization, but does not use a sample average approximation for optimizing a new candidatexi; instead, it uses an approximate sample path. See Rahimi & Recht [46] for details on RFFs. qNEHVI-1 is related to TSEMO in that both use sequential greedy batch selection using HVI based on RFF samples. However, TSEMO does not directly maximize HVI when selecting candidate xi, where i= 1,...,q ; rather, it relies on a heuristic approach of running NSGA-II on an RFF sample of each objective to create a discrete population of candidates and then selecting the point from the discrete population that maximizes HVI under the RFF sample. In contrast, qNEHVI-1 directly optimizes HVI under the RFF using exact sample-path gradients, which leads to improved optimiza- tion performance (see Appendix H). Furthermore, we ﬁnd that qNEHVI-1 is signiﬁcantly faster than TSEMO, because rather than using NSGA-II it uses second order gradient methods to optimize HVI (see Appendix H). Gradient-based optimization is only possible because CBD enables scalable, differentiable HVI computation. While the primary goal of this work is to develop a principled, scalable method for parallel EHVI in noisy environments, we include empirical comparisons with qNEHVI-1 throughout the appendix to demonstrate the generalizablility of the CBD approach and practical performance of the qNEHVI-1 approximation. qNEHVI-1 achieves the fastest batch selection timesof any method tested on a GPU on every problem; in many cases, this is an order of magnitude speed-up over qNEHVI . Moreover, qNEHVI-1 has a remarkable ability to scale to large batch sizes when the dimensionality of optimization problem is modest. Further investigation of qNEHVI-1 is needed, but we hope that the readers can recognize the ways in which qNEHVI can create broader opportunities for research into hypervolume improvement based acquisition functions. 9 Experiments We empirically evaluate qNEHVI on a set of synthetic and real-world benchmark problems. We compare it against the following recently proposed methods from the literature: PESMO, MESMO (which we extend to the handle noisy observations using the noisy information gain from Takeno et al. [52]), PFES, DGEMO, MOEA/D-EGO, TSEMO, TS-TCH, qEHVI (and qEHVI-PM-CBD , which uses the posterior mean as a plug-in estimate for the function values at the in-sample points, along with CBD to scale to large batch sizes), and qNParEGO. We optimize all methods using multi-start L-BFGS-B with exact gradients (except for PFES, which uses gradients approximated via ﬁnite differences), including TS-TCH where we optimize approximate function samples using RFFs with 500 basis functions. We model each outcome with an independent GP with a Matérn 5/2 ARD kernel and infer the GP hyperparameters via maximum a posteriori (MAP) estimation. For all problems, we assume that the noise variances are observed (except ABR, where we infer the noise level). See Appendix G for more details on the experiments and acquisition function implementations. We evaluate all methods using the logarithm of the difference in hypervolume between the true Pareto frontier and the approximate Pareto frontier recovered by the algorithm. Since evaluations are noisy, we compute the hypervolume dominated by the noiseless Pareto frontier across the observed points for each method. Synthetic Problems: We consider a noisy variants of the BraninCurrin problem (M = 2,d = 2) and the DTLZ2 problem (M = 2,d = 6) [13], in which observations are corrupted with zero-mean additive Gaussian noise with standard deviation of 5% of the range of each objective forBraninCurrin and 10% for DTLZ2. Adaptive Bitrate (ABR) Control Policy Optimization: ABR controllers are used for real-time communication and media streaming applications. Policies for these controllers must be tuned to 80 50 100 150 200 Function Evaluations 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75Log Hypervolume Difference BraninCurrin 0 50 100 150 200 Function Evaluations -1.10 -1.00 -0.90 -0.80 -0.70 -0.60 -0.50 -0.40 DTLZ2 0 50 100 150 200 Function Evaluations 4.80 5.00 5.20 5.40 5.60 5.80 ABR 0 50 100 150 200 Function Evaluations -1.00 -0.50 0.00 0.50 1.00 VehicleSafety DGEMO MESMO MOEA/D-EGO PESMO PFES TS-TCH TSEMO qEHVI qEHVI-PM-CBD qNEHVI qNEHVI-1 qNParEGO Figure 3: Sequential optimization performance. The shaded region indicates two standard errors of the mean over 100 replications (only 20 replications were feasible for PESMO due to large runtimes). deliver a high quality of experience with respect to multiple objectives [40]. In industry settings, A/B tests with dozens of policies are tested simultaneously since each policy may take days or weeks to evaluate, producing noisy measurements across multiple objectives. In this experiment, we tune policies to maximize video quality (bitrate) and minimize stall time. The policy hasd= 4 parameters, which are detailed in Appendix G. We use the Park simulator [ 41] and sample a random set of 100 traces to obtain noisy measurements of the objectives under a given policy. For comparing the performance of different methods, we estimate the true noiseless objective using mean objectives across 300 traces. We infer a homoskedastic noise level jointly with the GP hyperparameters via MAP estimation. Vehicle Design Optimization: Optimizing the design of the frame an automobile is important to maximizing passenger safety, vehicle durability and fuel efﬁciency. Evaluating a vehicle design is time-consuming, since either a vehicle must manufactured and crashed, or a nonlinear ﬁnite element-based crash analysis must be run to simulate a collision (which can take over 20 hours per run) [62]. Hence, evaluating many designs in parallel is critical for reducing end-to-end optimization time. Observations are often noisy due to manufacturing imperfections, measurement error, or non-deterministic simulations. In this experiment, we tune the d= 5 widths of various components of a vehicle’s frame to minimize proxy metrics for (1) fuel consumption, (2) passenger trauma in a full frontal collison, and (3) vehicle fragility [53]. See Appendix G for details. For this demonstration, we add zero-mean Gaussian noise with a standard deviation of 1% of the objective range, which roughly corresponds to the manufacturing noise level used in previous work [62]. 9.1 Summary of Results: We ﬁnd that qNEHVI and qNEHVI-1 outperform all other methods on the noisy benchmarks, both in the sequential and parallel setting. In the sequential setting (Fig 3), qNEHVI and qNEHVI-1 are followed closely by qEHVI -PM, and in some cases, even qEHVI . TS-TCH is ﬁrmly in the middle of the pack, while information-theoretic acquisition functions appear to perform the worst. This is consistent across noise levels; for experiments where we add noise to the objectives, we consider noise levels ranging from 1% to 10% of the range of each objective (these are magnitudes of the noise often seen in practice). Previous works have only evaluated MOBO algorithms with noise levels of 1% [25]. In Appendix H, we perform a study showing that qNEHVI consistently performs best with increasing noise levels up to 30% of the range of each objective. While parallel evaluation can provide optimization speedups on order of the batch size q, these evaluations do affect the overall sample complexity of the algorithm, since less information is available within the synchronous batch setting compared with fully sequential optimization. We ﬁnd that, by and large, qNEHVI achieves the greatest hyper-volume for increasingly large batch sizes, and scales more elegantly relative to TS-TCH and the ParEGO variants (Fig 4). qNEHVI also consistently outperforms qEHVI -PM-CBD. In Appendix H, we observe that qNEHVI and qNEHVI-1 provides excellent anytime performance all values ofqthat we tested. We provide results on 4 additional test problems in Appendix H.3, and in Appendix H.8, we demonstrate that leveraging CBD and a single sample path approximation, qNEHVI-1 enables scaling to 5-objective problems, which is a ﬁrst for an HVI-based method, to our knowledge. 91 8 16 32 q -0.25 0.00 0.25 0.50 0.75 1.00 1.25 1.50 Log Hypervolume Difference BraninCurrin 1 8 16 32 q -1.10 -1.00 -0.90 -0.80 -0.70 -0.60 -0.50 DTLZ2 1 8 16 32 q 4.70 4.80 4.90 5.00 5.10 5.20 ABR 1 8 16 32 q -1.00 -0.75 -0.50 -0.25 0.00 0.25 0.50 0.75 VehicleSafety DGEMO MOEA/D-EGO TS-TCH TSEMO qEHVI qEHVI-PM-CBD qNEHVI qNEHVI-1 qNParEGO Figure 4: The quality of the ﬁnal Pareto frontier identiﬁed by each method with increasing batch sizes qgiven a budget of 224 function evaluations. qEHVI is only included for q = 1 and q = 8 because the IEP scales exponential with q. DGEMO is omitted on the ABR problem because it was prohibitively slow with time-consuming ABR simulations and on the VehicleSafety problem because DGEMO consistently crashed in the graph cutting algorithm. In our experiments, we ﬁnd that qNEHVI-1 is among the top performers on relatively low- dimensional problems. Given the strong performance of qNEHVI-1 , we examine its performance as the dimensionality of the search space increases in Appendix H.5. We ﬁnd that qNEHVI is more robust than qNEHVI-1 in higher-dimensional search spaces, but further investigation is needed into how the number of the Fourier basis functions affects the performance ofqNEHVI-1 in high- dimensional search spaces. Optimization wall time: Across all experiments, we observe competitive wall times for optimizing qNEHVI and qNEHVI-1 (all wall time comparisons are provided in Appendix H). On a GPU, optimizing qNEHVI-1 incurs the lowest wall time of any method that we tested on every single problem and optimizing qNEHVI is faster than optimizing information-theoretic methods on all problems. Using efﬁcient low-rank Cholesky updates, qNEHVI is often faster than the qNParEGO implementation in BoTorch on a GPU. 10 Discussion We proposed NEHVI , a novel acquisition function that provides a principled approach to parallel and noisy multi-objective Bayesian optimization. NEHVI is a one-step Bayes-optimal policy for maximizing the hypervolume dominated by the Pareto frontier in noisy and noise-free settings. NEHVI is made feasible by a new approach to computing joint hypervolumes ( CBD ), and we demonstrated that CBD enables scalable, parallel candidate generation with both noiseless qEHVI and qNEHVI . We provide theoretical results on optimizing a MC estimator ofqNEHVI using sample average approximation and demonstrate signiﬁcant improvements in optimization performance over state-of-the-art MOBO algorithms. Yet, our work has some limitations. While the information-theoretic acquisition functions tested here perform poorly on our benchmarks, they do allow for decoupled evaluations of different objectives in cases where querying one objective may be more resource-intensive than querying other objectives. Optimizing such acquisition functions is a non-trivial task, and it is possible that with improved procedures, such acquisition functions could yield improved performance and provide a principled approach to selecting evaluation sources on a budget. Although practically fast enough for most Bayesian optimization tasks, exact hypervolume computation has super-polynomial complexity in the number of objectives. Combining qNEHVI with differentiable approximate methods for computing hypervolume (e.g. Couckuyt et al. [9], Golovin & Zhang [23]) could lead to further speed-ups. We hope that the core ideas presented in this work, including the CBD approach, can provide a framework to support the development of new computationally efﬁcient MOBO methods. 10References [1] Asadpour, A., Nazerzadeh, H., and Saberi, A. Stochastic submodular maximization. In Papadimitriou, C. and Zhang, S. (eds.), Internet and Network Economics . Springer Berlin Heidelberg, 2008. [2] Balandat, M., Karrer, B., Jiang, D. R., Daulton, S., Letham, B., Wilson, A. G., and Bakshy, E. BoTorch: A Framework for Efﬁcient Monte-Carlo Bayesian Optimization. In Advances in Neural Information Processing Systems 33, 2020. [3] Belakaria, S., Deshwal, A., and Doppa, J. R. Max-value entropy search for multi-objective bayesian optimization. In Advances in Neural Information Processing Systems 32, 2019. [4] Binois, M., Ginsbourger, D., and Roustant, O. Quantifying uncertainty on pareto fronts with gaussian process conditional simulations. Eur. J. Oper. Res., 243:386–394, 2015. [5] Bradford, E., Schweidtmann, A. M., and Lapkin, A. Efﬁcient multiobjective optimization employing gaussian processes, spectral sampling and a genetic algorithm. Journal of global optimization, 71(2):407–438, 2018. [6] Brockhoff, D., Tusar, T., Auger, A., and Hansen, N. Using well-understood single-objective functions in multiobjective black-box optimization test suites, 2019. [7] Calandra, R. and Peters, J. Pareto front modeling for sensitivity analysis in multi-objective bayesian optimization. 2014. [8] Calandra, R., Seyfarth, A., Peters, J., and Deisenroth, M. P. Bayesian optimization for learning gaits under uncertainty. Annals of Mathematics and Artiﬁcial Intelligence , 76(1):5–23, Feb 2016. ISSN 1573-7470. doi: 10 .1007/s10472-015-9463-9. [9] Couckuyt, I., Deschrijver, D., and Dhaene, T. Towards efﬁcient multiobjective optimization: Multiobjective statistical criterions. In 2012 IEEE Congress on Evolutionary Computation, pp. 1–8, 2012. [10] Daulton, S., Singh, S., Avadhanula, V ., Dimmery, D., and Bakshy, E. Thompson sampling for contextual bandit problems with auxiliary safety constraints. In NeurIPS Workshop on Safety and Robustness in Decision Making, 2019. [11] Daulton, S., Balandat, M., and Bakshy, E. Differentiable expected hypervolume improvement for parallel multi-objective Bayesian optimization. In Advances in Neural Information Processing Systems 33, NeurIPS, 2020. [12] Deb, K., Pratap, A., Agarwal, S., and Meyarivan, T. A fast and elitist multiobjective genetic algorithm: Nsga-ii. IEEE Transactions on Evolutionary Computation, 6(2):182–197, 2002. [13] Deb, K., Thiele, L., Laumanns, M., and Zitzler, E. Scalable multi-objective optimization test problems. volume 1, pp. 825–830, 06 2002. ISBN 0-7803-7282-4. doi: 10 .1109/ CEC.2002.1007032. [14] Deb, K., Gupta, S., Daum, D., Branke, J., Mall, A. K., and Padmanabhan, D. Reliability-based optimization using evolutionary algorithms. IEEE Transactions on Evolutionary Computation, 13(5):1054–1074, 2009. doi: 10 .1109/TEVC.2009.2014361. [15] Dächert, K., Klamroth, K., Lacour, R., and Vanderpooten, D. Efﬁcient computation of the search region in multi-objective optimization. European Journal of Operational Research, 260 (3):841 – 855, 2017. [16] Emmerich, M. T. M., Giannakoglou, K. C., and Naujoks, B. Single- and multiobjective evolutionary optimization assisted by gaussian random ﬁeld metamodels. IEEE Transactions on Evolutionary Computation, 10(4):421–439, 2006. [17] Feng, Q., Letham, B., Bakshy, E., and Mao, H. High-Dimensional Contextual Policy Search with Unknown Context Rewards using Bayesian Optimization. In Advances in Neural Information Processing Systems 33, 2020. [18] Fisher, M. L., Nemhauser, G. L., and Wolsey, L. A. An analysis of approximations for maximizing submodular set functions—II , pp. 73–87. Springer Berlin Heidelberg, Berlin, Heidelberg, 1978. [19] Frazier, P. I. A tutorial on bayesian optimization. arXiv preprint arXiv:1807.02811, 2018. 11[20] Garrido-Merchán, E. C. and Hernández-Lobato, D. Predictive entropy search for multi-objective bayesian optimization with constraints. Neurocomputing, 361:50–68, 2019. [21] Garrido-Merchán, E. C. and Hernández-Lobato, D. Parallel predictive entropy search for multi-objective bayesian optimization with constraints, 2020. [22] Gelbart, M. A., Snoek, J., and Adams, R. P. Bayesian optimization with unknown constraints. In Proceedings of the 30th Conference on Uncertainty in Artiﬁcial Intelligence, UAI, 2014. [23] Golovin, D. and Zhang, Q. Random hypervolume scalarizations for provable multi-objective black box optimization, 2020. [24] Hernández-Lobato, J. M., Hoffman, M. W., and Ghahramani, Z. Predictive entropy search for efﬁcient global optimization of black-box functions. In Proceedings of the 27th International Conference on Neural Information Processing Systems - Volume 1 , NIPS’14, pp. 918–926, Cambridge, MA, USA, 2014. MIT Press. [25] Hernández-Lobato, D., Hernández-Lobato, J. M., Shah, A., and Adams, R. P. Predictive entropy search for multi-objective bayesian optimization, 2015. [26] Horn, D., Dagge, M., Sun, X., and Bischl, B. First investigations on noisy model-based multi- objective optimization. volume 10173, pp. 298–313, 02 2017. ISBN 978-3-319-54156-3. doi: 10.1007/978-3-319-54157-0_21. [27] Igel, C., Hansen, N., and Roth, S. Covariance matrix adaptation for multi-objective optimization. Evolutionary Computation, 15(1):1–28, 2007. doi: 10 .1162/evco.2007.15.1.1. [28] Jiang, S., Zhang, H., Cong, W., Liang, Z., Ren, Q., Wang, C., Zhang, F., and Jiao, X. Multi- objective optimization of smallholder apple production: Lessons from the bohai bay region. Sustainability, 12(16):6496, 2020. [29] Jones, D. R., Schonlau, M., and Welch, W. J. Efﬁcient global optimization of expensive black-box functions. Journal of Global Optimization, 13:455–492, 1998. [30] Kingma, D. P. and Welling, M. Auto-Encoding Variational Bayes. arXiv e-prints , pp. arXiv:1312.6114, Dec 2013. [31] Klamroth, K., Lacour, R., and Vanderpooten, D. On the representation of the search region in multi-objective optimization. European Journal of Operational Research, 245(3):767–778, Sep 2015. ISSN 0377-2217. doi: 10 .1016/j.ejor.2015.03.031. URL http://dx.doi.org/ 10.1016/j.ejor.2015.03.031. [32] Knowles, J. Parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems. IEEE Transactions on Evolutionary Computation, 10(1): 50–66, 2006. [33] Koch, P., Wagner, T., Emmerich, M. T., Back, T., and Konen, W. Efﬁcient multi-criteria optimization on noisy machine learning problems. Appl. Soft Comput., 29(C):357–370, April 2015. ISSN 1568-4946. doi: 10 .1016/j.asoc.2015.01.005. URL https://doi.org/10.1016/ j.asoc.2015.01.005. [34] Lacour, R., Klamroth, K., and Fonseca, C. M. A box decomposition algorithm to compute the hypervolume indicator. Computers & Operations Research, 79:347 – 360, 2017. [35] LeCun, Y ., Cortes, C., and Burges, C. Mnist handwritten digit database.ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist, 2, 2010. [36] Letham, B. and Bakshy, E. Bayesian optimization for policy search via online-ofﬂine ex- perimentation. Journal of Machine Learning Research , 20(145):1–30, 2019. URL http: //jmlr.org/papers/v20/18-225.html. [37] Letham, B., Karrer, B., Ottoni, G., and Bakshy, E. Constrained bayesian optimization with noisy experiments. Bayesian Analysis, 14(2):495–519, 06 2019. doi: 10 .1214/18-BA1110. [38] Liao, T., Wang, G., Yang, B., Lee, R., Pister, K., Levine, S., and Calandra, R. Data-efﬁcient learning of morphology and controller for a microrobot. In 2019 International Conference on Robotics and Automation (ICRA), pp. 2488–2494. IEEE, 2019. [39] Lukovic, K. M., Tian, Y ., and Matusik, W. Diversity-guided multi-objective bayesian opti- mization with batch evaluations. Advances in Neural Information Processing Systems , 33, 2020. 12[40] Mao, H., Chen, S., Dimmery, D., Singh, S., Blaisdell, D., Tian, Y ., Alizadeh, M., and Bakshy, E. Real-world video adaptation with reinforcement learning. 2019. [41] Mao, H., Negi, P., Narayan, A., Wang, H., Yang, J., Wang, H., Marcus, R., Addanki, R., Shirkoohi, M. K., He, S., Nathan, V ., Cangialosi, F., Venkatakrishnan, S. B., Weng, W.-H., Han, S.-W., Kraska, T., and Alizadeh, M. Park: An open platform for learning-augmented computer systems. In NeurIPS, 2019. [42] Mennen, S. M., Alhambra, C., Allen, C. L., Barberis, M., Berritt, S., Brandt, T. A., Campbell, A. D., Castañón, J., Cherney, A. H., Christensen, M., Damon, D. B., Eugenio de Diego, J., García-Cerrada, S., García-Losada, P., Haro, R., Janey, J., Leitch, D. C., Li, L., Liu, F., Lobben, P. C., MacMillan, D. W. C., Magano, J., McInturff, E., Monfette, S., Post, R. J., Schultz, D., Sitter, B. J., Stevens, J. M., Strambeanu, I. I., Twilton, J., Wang, K., and Zajac, M. A. The evolution of high-throughput experimentation in pharmaceutical development and perspectives on the future. Organic Process Research & Development, 23(6):1213–1242, 2019. doi: 10.1021/acs.oprd.9b00140. [43] Namkoong, H., Daulton, S., and Bakshy, E. Distilled thompson sampling: Practical and efﬁcient thompson sampling via imitation learning. In NeurIPS Ofﬂine Reinforcement Learning Workshop, 2020. [44] Osborne, M. A. Bayesian gaussian processes for sequential prediction, optimisation and quadrature. 2010. [45] Paria, B., Kandasamy, K., and Póczos, B. A Flexible Multi-Objective Bayesian Optimization Approach using Random Scalarizations. ArXiv e-prints, May 2018. [46] Rahimi, A. and Recht, B. Random features for large-scale kernel machines. In Proceedings of the 20th International Conference on Neural Information Processing Systems, NIPS’07, pp. 1177–1184, Red Hook, NY , USA, 2007. Curran Associates Inc. ISBN 9781605603520. [47] Rasmussen, C. E. Gaussian Processes in Machine Learning , pp. 63–71. Springer Berlin Heidelberg, Berlin, Heidelberg, 2004. [48] Real, E., Aggarwal, A., Huang, Y ., and Le, Q. V . Regularized evolution for image classiﬁer architecture search. Proceedings of the AAAI Conference on Artiﬁcial Intelligence , 33(01): 4780–4789, Jul. 2019. doi: 10 .1609/aaai.v33i01.33014780. URL https://ojs.aaai.org/ index.php/AAAI/article/view/4405. [49] Schuster, M. Speech recognition for mobile devices at google. In Zhang, B.-T. and Orgun, M. A. (eds.), PRICAI 2010: Trends in Artiﬁcial Intelligence, pp. 8–10, Berlin, Heidelberg, 2010. Springer Berlin Heidelberg. ISBN 978-3-642-15246-7. [50] Shahriari, B., Swersky, K., Wang, Z., Adams, R. P., and de Freitas, N. Taking the human out of the loop: A review of bayesian optimization. Proceedings of the IEEE, 104(1):148–175, 2016. [51] Suzuki, S., Takeno, S., Tamura, T., Shitara, K., and Karasuyama, M. Multi-objective Bayesian optimization using pareto-frontier entropy. In III, H. D. and Singh, A. (eds.), Pro- ceedings of the 37th International Conference on Machine Learning , volume 119 of Pro- ceedings of Machine Learning Research , pp. 9279–9288. PMLR, 13–18 Jul 2020. URL http://proceedings.mlr.press/v119/suzuki20a.html. [52] Takeno, S., Fukuoka, H., Tsukada, Y ., Koyama, T., Shiga, M., Takeuchi, I., and Karasuyama, M. Multi-ﬁdelity Bayesian optimization with max-value entropy search and its parallelization. In III, H. D. and Singh, A. (eds.), Proceedings of the 37th International Conference on Machine Learning, volume 119 of Proceedings of Machine Learning Research, pp. 9334–9345. PMLR, 13–18 Jul 2020. URL http://proceedings.mlr.press/v119/takeno20a.html. [53] Tanabe, R. and Ishibuchi, H. An easy-to-use real-world multi-objective optimization problem suite. Applied Soft Computing, 89:106078, 2020. ISSN 1568-4946. doi: https://doi.org/10.1016/ j.asoc.2020.106078. [54] Thompson, W. R. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 25(3/4):285–294, 1933. [55] Touré, C., Hansen, N., Auger, A., and Brockhoff, D. Uncrowded hypervolume improvement: Como-cma-es and the sofomore framework. In Proceedings of the Genetic and Evolutionary Computation Conference, GECCO ’19, pp. 638–646, New York, NY , USA, 2019. Association for Computing Machinery. ISBN 9781450361118. doi: 10 .1145/3321707.3321852. URL https://doi.org/10.1145/3321707.3321852. 13[56] Wang, R., Xiong, J., Ishibuchi, H., Wu, G., and Zhang, T. On the effect of reference point in moea/d for multi-objective optimization. Applied Soft Computing , 58:25–34, 2017. ISSN 1568-4946. doi: https://doi .org/10.1016/j.asoc.2017.04.002. URL https: //www.sciencedirect.com/science/article/pii/S1568494617301722. [57] Wilson, J., Hutter, F., and Deisenroth, M. Maximizing acquisition functions for bayesian optimization. In Advances in Neural Information Processing Systems 31, pp. 9905–9916. 2018. [58] Yang, K., Emmerich, M., Deutz, A., and Bäck, T. Multi-objective bayesian global optimization using expected hypervolume improvement gradient. Swarm and Evolutionary Computation, 44: 945 – 956, 2019. ISSN 2210-6502. doi: https://doi .org/10.1016/j.swevo.2018.10.007. [59] Yang, K., Emmerich, M., Deutz, A. H., and Bäck, T. Efﬁcient computation of expected hypervolume improvement using box decomposition algorithms. CoRR, abs/1904.12672, 2019. [60] Yang, K., Palar, P., Emmerich, M., Shimoyama, K., and Bäck, T. A multi-point mechanism of expected hypervolume improvement for parallel multi-objective bayesian global optimization. pp. 656–663, 07 2019. doi: 10 .1145/3321707.3321784. [61] Yang, K., Palar, P. S., Emmerich, M., Shimoyama, K., and Bäck, T. A multi-point mech- anism of expected hypervolume improvement for parallel multi-objective bayesian global optimization. In Proceedings of the Genetic and Evolutionary Computation Conference , GECCO ’19, pp. 656–663, New York, NY , USA, 2019. Association for Computing Machinery. ISBN 9781450361118. doi: 10 .1145/3321707.3321784. URL https://doi.org/10.1145/ 3321707.3321784. [62] Youn, B. D., Choi, K., Yang, R.-J., and Gu, L. Reliability-based design optimization for crashworthiness of vehicle side impact. Structural and Multidisciplinary Optimization , 26: 272–283, 02 2004. doi: 10 .1007/s00158-003-0345-0. [63] Zhang, G. and Block, D. E. Using highly efﬁcient nonlinear experimental design methods for optimization of lactococcus lactis fermentation in chemically deﬁned media. Biotechnology progress, 25(6):1587–1597, 2009. [64] Zhang, Q., Liu, W., Tsang, E., and Virginas, B. Expensive multiobjective optimization by moea/d with gaussian process model. IEEE Transactions on Evolutionary Computation, 14(3): 456–474, 2010. doi: 10 .1109/TEVC.2009.2033671. [65] Zhou, A., Zhang, Q., and Zhang, G. A multiobjective evolutionary algorithm based on decom- position and probability model. In 2012 IEEE Congress on Evolutionary Computation, pp. 1–8, 2012. doi: 10 .1109/CEC.2012.6252954. [66] Zitzler, E., Deb, K., and Thiele, L. Comparison of multiobjective evolutionary algorithms: Empirical results. Evol. Comput., 8(2):173–195, June 2000. ISSN 1063-6560. doi: 10 .1162/ 106365600568202. URL https://doi.org/10.1162/106365600568202. [67] Zitzler, E., Deb, K., and Thiele, L. Comparison of multiobjective evolutionary algorithms: Empirical results. Evolutionary computation, 8(2):173–195, 2000. 14Appendix to: Parallel Bayesian Optimization of Multiple Noisy Objectives with Expected Hypervolume Improvement A Potential Societal Impact Bayesian Optimization speciﬁcally aims to increase sample efﬁciency for hard optimization algo- rithms, and consequently can help achieve better solutions without incurring large societal costs. For instance, as demonstrated in this work, automotive design problems may be solved much faster, reducing the amount of computationally costly simulations and thus the energy footprint during development. At the same time, improved solutions mean that high crash safety can be achieved with lighter cars, resulting in fewer resources required for their production and, importantly, improving fuel economy of the whole vehicle ﬂeet. Increased robustness to noisy observations further helps reduce the resources spent on evaluating regions of the search space that are not promising. Improvements to the optimization performance and practicality of multi-objective Bayesian optimization have the potential to allow decision makers to better understand and make more informed decisions across multiple trade-offs. We expect these directions to be particularly important as Bayesian optimization is increasingly used for applications such as recommender systems [36], where auxiliary goals such as fairness must be accounted for. Of course, at the end of the day, exactly what objectives decision makers choose to optimize, and how they balance those trade-offs (and whether that is done in equitable fashion) is up to the individuals themselves. B Computing Hypervolume Improvement with Box Decompositions Deﬁnition 3. For a set of objective vectors {f(xi)}q i=1, a reference point r∈RM, and a Pareto frontier P, let ∆({f(xi)}q i=1,P,r) ⊂ RM denote the set of points (1) that are dominated by {f(xi)}q i=1, (2) that dominate r, and (3) that are not dominated by P. Let {S1,...,S K}be a set ofKdisjoint axis-aligned rectangles where each Sk is deﬁned by a pair of lower and upper vertices lk ∈RM and uk ∈RM ∪{∞}. Figure 5 shows an example decomposition. Such a partitioning allows for efﬁcient piece-wise computation of the hypervolume improvement from a new point f(xi) by computing the volume of the intersection of the region dominated exclusively by the new point with ∆({f(xi),P,r) (and not dominated by the P) with each hyperrectangle Sk. Although ∆(f(xi),P,r) is a non-rectangular polytope, the intersection of∆(f(xi),P,r) with each rectangle Sk is a rectangular polytope and the vertices bounding the hyperrectangle corresponding to ∆(f(xi),P,r) ∩Sk can be easily computed: the lower bound vertex is lk and the upper bound vertex is the component-wise minimum of uk and the new point f(x): zk := min [ uk,f(x) ] . The hypervolume improvement can be computed by summing over the volume of∆(f(xi),P,r) ∩Sk over all Sk HVI ( f(x),P ) = K∑ k=1 HVI k ( f(x),lk,uk ) = K∑ k=1 M∏ m=1 [ z(m) k −l(m) k ] +, (7) where [·]+ denotes the max(·,0) operation. 15f(x) r l3 S3 u3u2 S2 l2 l4 S4 u4u1 l1 S1 f (2)(x) f (1)(x) f(x1) f(x2) f(x3) Figure 5: The hypervolume improvement from a new point f(x) is shown in blue. The current Pareto frontier Pis given by the green points, the green area is the hypervolume of the Pareto frontier Pgiven reference point r. The white rectangles S1,...,S k are a disjoint, box decomposition of the non-dominated space that can be used to efﬁciently compute the hypervolume improvement. C qNEHVI under Different Computational Approaches C.1 Derivation of IEP formulation of qNEHVI From (4), the expected noisy joint hypervolume improvement is given by ˆαqNEHVI (Xcand) = 1 N N∑ t=1 HVI ( ˜ft(Xcand)|Pt) Recall that the joint HVI formulation under the IEP derived by Daulton et al. [11] is given by HVI (f(Xcand)|P) = K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 M∏ m=1 [ z(m) k,Xj −l(m) k ] + (8) where Xj := {Xj ⊆Xcand : |Xj|= j}and z(m) k,t,Xj := min[ u(m) k,t ,f(m)(xi1 ),...,f (m)(xij )] for Xj = {xi1 ,..., xij }. In qNEHVI , the lower and upper bounds and the number of rectangles in each box decomposition depend Pt. Hence, ˆαqNEHVI (Xcand) = 1 N N∑ t=1 Kt∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 M∏ m=1 [ z(m) k,t,Xj −l(m) k,t ] + where z(m) k,t,Xj := min[u(m) k,t , ˜f(m) t (xi1 ),..., ˜f(m) t (xij )] for Xj = {xi1 ,..., xij }. C.2 Derivation of CBD formulation of qNEHVI Using Deﬁnition 2, we rewrite (4) as ˆαqNEHVI (Xcand) = 1 N N∑ t=1 HVI ( ˜ft(Xcand)|Pt) = 1 N N∑ t=1 [ HV( ˜f(Xcand) ∪Pt) −HV(Pt) ] Adding and subtracting HV( ˜f({x1),..., ˜f(xq−1)}) ∪Pt) yields ˆαqNEHVI (Xcand) = 1 N N∑ t=1 [ HV( ˜f(Xcand) ∪Pt) −HV( ˜f({x1),..., ˜f(xq−1)}) ∪Pt) + HV({˜f(x1),..., ˜f(xq−1)}∪Pt) −HV(Pt) ] . 16Applying Deﬁnition 2 again leads to (6): ˆαqNEHVI (Xcand) = 1 N N∑ t=1 HVI( ˜f(xq)|{˜f(x1),..., ˜f(xq−1)}∪Pt) + 1 N N∑ t=1 HVI ({˜f(x1),..., ˜f(xq−1)})|Pt). Note that using the method of common random numbers, the CBD formulation is mathematically equivalent to IEP formulation, but the computing qNEHVI with the CBD trick is much more efﬁcient. D Complexity Analysis D.1 Complexity of Computing qNEHVI In this section we study the complexity of computing the acquisition function. For brevity, we omit the cost of posterior sampling, which is the same for the CBD and IEP approaches. 6 The CBD approach requires recomputing box decompositions when generating each new candidate. In the worst case, each new candidate is Pareto optimal under the ﬁxed posterior samples, which leads to a time complexity of O ( N(n+ i)M) for computing the box decompositions in iteration i[59]. Note that there are O ( (n+ i)M) rectangles in each box decomposition. Given box decompositions and posterior samples at the new point, the complexity of computing the acquisition function on a single-threaded machine is O ( MN(n+ i)M) . Hence, the total time complexity for generating q candidates (ignoring potentially additional time complexity for automated gradient computations) is O ( N q∑ i=1 (n+ i)M ) + O ( NoptMN q∑ i=1 (n+ i)M ) = O ( NoptNM(n+ q)Mq ) , (9) O ( NnM) + O ( NoptMNnM q∑ i=1 2i−1 ) = O ( NoptNMnM2qq ) . (10) The second term on the left hand side in both (9) and (10) is the acquisition optimization complexity, which boils down to O(Nopt) given inﬁnite computing cores because the acquisition computation is completely parallelizable. However, as shown in Figure 2, even for relatively small values ofq, CPU cores become saturated and GPU memory limits are reached. Everything else ﬁxed, the asymptotic relative time complexity of using CBD over IEP is therefore q−M2q →∞ as q→∞. Similarly, the space complexity under the CBD formulation, O ( MN(n+ q)M) , is also polynomial in q, whereas the space complexity is exponential in qunder the IEP formulation: O ( MNnMq2q) . Everything else ﬁxed, the asymptotic relative complexity (both in terms of time and space) of using CBD over IEP is therefore qM2−q →0 as q→∞. D.2 Efﬁcient Batched Computation As noted above, using either the IEP or CBD approach, the acquisition computation given the box decompositions is highly parallelizable. However, since the number of hyperrectangles Kt in the box decompoosition can be different under each posterior sample ˜ft, stacking the box decompositions does not result in a rectangular matrix; the matrix is ragged. In order to leverage modern batched 6Sampling from p(f(Xn)|Dn) incurs a one-time cost of O(Mn3) if each of the M outcomes is modeled by an independent GP, as it involves computing a Cholesky decomposition of the n×n posterior covari- ance (at the n observed points) for each. Using low-rank updates of the Cholesky factor to sample from p(f(Xn,x0,..., xi)|Dn) has a time complexity of O(M(n+ i−1)2) for 1 ≤i ≤qsince each triangular solve has quadratic complexity. Sampling is more costly when using a multi-task GP model, as it requires a root decomposition of the Mn ×Mn posterior covariance across data points and tasks. 17tensor computational paradigms, we pad the box decompositions with empty hyperrectangles (e.g. l = 0,u = 0) such that the box decomposition under every posterior sample contains exactly K = max tKt hyperrectangles, which allows us to deﬁne a t×K dimensional matrix of box decompositions for use in batched tensor computation. In the 2-objective case, instead of padding the box decomposition, the Pareto frontier under each posterior sample can be padded instead by repeating a point on the Pareto Frontier such that the padded Pareto frontier under every posterior sample has exactly maxt|Pt|points. This enables computing the box decompositions analytically for all posterior samples in parallel using efﬁcient batched computation. The resulting box decompositions all have K = maxt|Pt|+ 1hyperrectangles (some of which may be empty). E Theoretical Results Let xprev ∈Rnd denote the stacked set of previously evaluated points in Xn: xprev := [xT 1 ,..., xT n]T. Similarly, let xcand ∈Rqd denote the stacked set of candidates in Xcand: xcand := [xT n+1,..., xT n+q]T. Let ˜ft(xprev,xcand) := [ ˜ft(x1)T,..., ˜ft(xn+q)T]T denote the tth sample of the corresponding objec- tives, which we write using the parameterization trick as ft(xprev,xcand) = µ(xprev,xcand) + L(xprev,xcand)ζt, where µ(xprev,xcand) : R(n+q)d → R(n+q)M is the multi-output GP’s posterior mean and L(xcand,xprev) ∈R(n+q)M×(n+q)M is a root decomposition (often a Cholesky decomposition) of the multi-output GP’s posterior covarianceΣ(xcand,xprev) ∈R(n+q)M×(n+q)M, and ζt ∈R(n+q)M with ζt ∼N(0,I(n+q)M).7 Proof of Theorem 1. Since the sequential NEHVI is equivalent to the qNEHVI with q = 1, we prove Theorem 1 for the general q >1 case. Recall from Section C.2, that using the method of common random numbers to ﬁx the base samples, the IEP and CBD formulations are equivalent. Therefore, we proceed only with the IEP formulation for this proof. We closely follow the proof of Theorem 2 in Daulton et al.[11]. We consider the setting from Balandat et al. [2, Section D.5]. Let f(m) t (xi,ζt) = S{i,m}(µ(xcand,xprev) + L(xcand,xprev)ζt) denote the posterior distribution over the mth outcome at xi as a random variable, where S{i,m}denotes the selection matrix (∥S{i,m}∥∞≤1 for all i= 1,...,n + qand m= 1,...,M ), to extract the element corresponding to outcome mfor the point xi. The HVI under a single posterior sample is given by A(xcand,ζt; xprev) = Kt∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 M∏ m=1 [ z(m) k,Xj (ζt) −l(m) k ] + where Xj := {Xj = {xi1 ,...xij } ⊆ Xcand : |Xj| = j,n + 1 ≤ i1 ≤ ij ≤ n + q}and z(m) k,Xj (ζt) = min [ u(m) k ,f(m)(xi1 ,ζt),...,f (m)(xij ,ζt) ] . Note that the box decomposition of the non-dominated space {S1,...,S Kt}and the number of rectangles in the box decomposition depend on ζt. Importantly, the number of hyperrectangles Kt in the decomposition is a ﬁnite and bounded by O(|Pt|⌊M 2 ⌋+1) [34, 59], where |Pt|≤ n. To satisfy the conditions of [2, Theorem 3], we need to show that there exists an integrable function ℓ: Rq×M ↦→R such that for almost every ζt and all xcand,ycand ⊆X, |A(xcand,ζt; xprev) −A(ycand,ζt; xprev)|≤ ℓ(ζt)∥xcand −ycand∥. (11) We note that xprev is ﬁxed and omit xprev for brevity, except where necessary. Let ˜ak,m,j,Xj (xcand,ζt) := [ min [ u(m) k,t ,f(m)(xi1 ,ζt),...,f (m)(xij ,ζt) ] −l(m) k,t ] + . 7Theorem 1 can be extended to handle non-iidbase samples from a family of quasi-Monte Carlo methods as in Balandat et al. [2]. 18Because of linearity, it sufﬁces to show that this condition holds for ˜A(xcand,ζt) := M∏ m=1 ˜ak,m,j,Xj (xcand,ζt) = M∏ m=1 [ min [ u(m) k,t ,f(m)(xi1 ,ζt),...,f (m)(xij ,ζt) ] −l(m) k,t ] + (12) for all k,j, and Xj. Note that we can bound ˜ak,m,j,Xj (xcand,ζt) by ˜ak,m,j,Xj (xcand,ζt) ≤ ⏐⏐⏐min [ u(m) k,t ,f(m)(xi1 ,ζt),...,f (m)(xij ,ζt) ] −l(m) k,t ⏐⏐⏐ ≤|l(m) k,t |+ ⏐⏐⏐min [ u(m) k,t ,f(m)(xi1 ,ζt),...,f (m)(xij ,ζt) ]⏐⏐⏐. (13) Consider the case where u(m) k,t = ∞. Then min[u(m) k,t ,f(xi1 ,ζt)(m),...,f (m)(xij ,ζt)] = min[f(m)(xi1 ,ζt),...,f (m)(xij ,ζt)]. Now suppose u(m) k,t <∞. Then min[u(m) k,t ,f(m)(xi1 ,ζt),...f(m)(xij ,ζt)] < ⏐⏐min[f(m)(xi1 ,ζt),...f(m)(xij ,ζt)] ⏐⏐+ ⏐⏐u(m) k,t ⏐⏐. Let w(m) k,t = { u(m) k,t , if u(m) k,t <∞ 0, otherwise. Note that l(m) k,t is ﬁnite and bounded from above and below by r(m) ≤l(m) k,t < u(m) k,t for all k,t,m , where r(m) is the mth dimension of the reference point. Hence, we can express the bound in (13) as ˜ak,m,j,Xj (xcand,ζt) ≤|l(m) k,t |+ |w(m) k,t |+ ⏐⏐min [ f(m)(xi1 ,ζt),...,f (m)(xij ,ζt) ]⏐⏐ ≤|l(m) k,t |+ |w(m) k,t |+ ∑ i1,...,ij ⏐⏐f(m)(xij ,ζt) ⏐⏐. (14) Note that we can bound ∑ i1,...,ij ⏐⏐f(m)(xij ,ζt) ⏐⏐by ∑ i1,...,ij ⏐⏐f(m)(xij ,ζt) ⏐⏐≤|Xj| ( ∥µ(m)(xcand,xprev)∥+ ∥L(m)(xcand,xprev)∥∥ζt∥ ) . Substituting this into (14) yields |˜ak,m,j,Xj (xcand,ζt)|≤| l(m) k,t |+ |w(m) k,t |+ |Xj| ( ∥µ(m)(xcand,xprev)∥+ ∥L(m)(xcand,xprev)∥∥ζt∥ ) (15) for all k,m,j,X j. Because of our assumptions of that X is compact and that the mean and covariance func- tions are continuously differentiable, µ(xcand,xprev),L(xcand,xprev),∇xcand µ(xcand,xprev), and ∇xcand L(xcand,xprev) are uniformly bounded. Hence, there exist C1,C2 <∞such that |˜ak,m,j,Xj (xcand,ζt)|≤ C1 + C2∥ζt∥ for all k,m,j,X j. Consider the M = 2 case. Omitting the indices k,t,j,X j for brevity, we have ⏐⏐˜A(xcand,ζt)−˜A(ycand,ζt) ⏐⏐ = ⏐⏐˜a1(xcand,ζt)˜a2(xcand,ζt) −˜a1(ycand,ζt)˜a2(ycand,ζt) ⏐⏐ = ⏐⏐˜a1(xcand,ζt) ( ˜a2(xcand,ζt) −˜a2(ycand,ζt) ) + ˜a2(ycand,ζt) ( ˜a1(xcand,ζt) −˜a1(ycand,ζt) )⏐⏐ ≤|˜a1(xcand,ζt)| ⏐⏐˜a2(xcand,ζt) −˜a2(ycand,ζt) ⏐⏐+ |˜a2(ycand,ζt)| ⏐⏐˜a1(xcand,ζt) −˜a1(ycand,ζt) ⏐⏐. (16) 19Using (15), we can bound |˜ak,m,j,Xj (xcand,ζt) −˜akmjXj (ycand,ζt)|by |˜ak,t,m,j,Xj (xcand,ζt) −˜ak,t,m,j,Xj (ycand,ζt)| ≤ ∑ i1,...,ij ⏐⏐S{ij,m}(µ(xcand,xprev) + L(xcand,xprev)ζt) −S{ij,m}(µ(ycand,xprev) + L(ycand,xprev)ζt) ⏐⏐ ≤|Xj| ( ∥µ(xcand,xprev) −µ(ycand,xprev)∥+ ∥L(xcand,xprev) −L(ycand,xprev)∥∥ζt∥ ) . Since µand Lhave uniformly bounded gradients with respect to xcand and ycand, they are Lipschitz. Therefore, there exist C3,C4 <∞such that |˜ak,t,m,j,Xj (xcand,ζt) −˜ak,t,m,j,Xj (ycand,ζt)|≤ (C3 + C4∥ζt∥)∥xcand −ycand∥ (17) for all xcand,ycand,k,t,m,j,X j. Substituting (17) into (16), we have ⏐⏐˜A(xcand,ζt) −˜A(ycand,ζt) ⏐⏐≤2 ( C1C3 + (C1C4 + C2C3)∥ζt∥+ C2C4∥ζt∥2 ) ∥xcand −ycand∥ The M >2 is very similar to theM = 2 case in (16) albeit with more complex expansions. Similarly, There exist C <∞such that ⏐⏐˜A(xcand,ζt) −˜A(ycand,ζt) ⏐⏐≤C M∑ m=1 ∥ζt∥m∥xcand −ycand∥ Let us deﬁne ℓ(ζt) := C∑M m=1 ∥ζt∥m. Note that ℓ(ζt) is integrable because all absolute moments exist for the Gaussian distribution. Since this satisﬁes the criteria for Theorem 3 in Balandat et al. [2], the theorem holds for qNEHVI. E.1 Unbiased Gradient estimates from the MC formulation As noted in Section 7, we can show the following (note that this result is not actually required for Theorem 1): Proposition 1. Suppose that the GP mean and covariance function are continuously differentiable. Suppose further that the candidate set Xcand has no duplicates, and that the sample-level gradients ∇xHVI ( ˜ft(x)) are obtained using the reparameterization trick as in Balandat et al. [2]. Then E [ ∇xcand ˆαN qNEHVI (xcand) ] = ∇xcand αqNEHVI (xcand), (18) that is, the averaged sample-level gradient is an unbiased estimate of the gradient of the true acquisition function. The proof of Proposition 1 closely follows the proof of Proposition 1 in Daulton et al. [11]. F Error Bound on Sequential Greedy Approximation for NEHVI If the acquisition function L(Xcand) is a normalized (meaning L(∅) = 0 ), monotone, submodu- lar (meaning that the increase in L(Xcand) is non-increasing as elements are added to Xcand set function), then the sequential greedy approximation ˆLof Lenjoys regret of no more than 1 eL∗, where L∗= maxXcand⊆XL(Xcand) is the optima of L[18]. We have αqNEHVI (Xcand) = L(Xcand) = EP [ αqEHVI (Xcand|P) ] . For a ﬁxed, known P, Daulton et al. [11] showed that αqEHVI is submodu- lar set function. In αqNEHVI , Pis a stochastic, so αqEHVI (Xcand|P) is a stochastic submodular set function. Because the expectation of a stochastic submodular function is submodular [1], αqNEHVI is also submodular. Hence, the sequential greedy approximation of αqNEHVI enjoys regret of no more than 1 eαqNEHVI ∗. Using the result from Wilson et al. [57], the MC-based approximation ˆαqNEHVI (Xcand) = ∑N t=1 HVI [ ft(Xcand)|Pt ] also enjoys the same regret bound because HVI is a normalized submodular set function.8 8Submodularity technically requires a ﬁnite search space X, whereas in BO Xis typically an inﬁnite set. Nevertheless in similar scenarios, submodularity has been extended to inﬁnite sets (e.g. Wilson et al. [57]). 20G Experiment Setup G.1 Implementation / Code used in the experiments Our implementations of qNEHVI , MESMO, PFES are available in the supplementary ﬁles and will be open-sourced under MIT license upon publication. For PESMO, we use the open-source imple- mentation in Spearmint (https://github.com/HIPS/Spearmint/tree/PESM), which is licensed by Harvard. For DGEMO, MOEA/D-EGO, and TSEMO we use the open-source implementations available at https://github.com/yunshengtian/DGEMO/tree/master under the MIT license. For TS-TCH, qEHVI , and qNParEGO we use the open-source implementations in BoTorch, which are available at https://github.com/pytorch/botorch) under the MIT license. For the ABR problem, we use the Park simulator, which is available in open-source at https: //github.com/park-project/park under the MIT license. G.2 Algorithm Details All methods are initialized with2(d+1) points from a scrambled Sobol sequence. All MC acquisition functions uses N = 128 quasi-MC samples [2]. All parallel algorithms using sequential greedy optimization for selecting a batch of candidates points and the base samples are redrawn when selecting candidate xi,i = 1,...,q . For EHVI-based methods, we leverage the two-step trick proposed by [ 59] to perform efﬁcient box decompositions; (i) we ﬁnd the set of local lower bounds for the maximization problem using Algorithm 5 from Klamroth et al. [31]9, and then (ii) using the local lower bounds as a Pareto frontier for the artiﬁcial minimization problem, we compute a box decomposition of the dominated space using Algorithm 1 from Lacour et al. [34]. qEHVI uses the IEP for computing joint EHVI over a set of candidates and computes EHVI with respect to the observed Pareto frontier. qEHVI-PM-CBD uses the Pareto frontier over the posterior means at the previously evaluated points, providing some amount of regularization with respect to the observed values. In addition, qEHVI-PM-CBD uses CBD rather than the IEP , which enables scaling to large batch sizes. qNEHVI-1 uses 500 fourier basis functions. For PFES and MESMO, we use 10 sampled (approximate) functions using RFFs (with 500 basis functions) and optimize each function using 5000 iterations of NSGA-II [12] with a population size of 50. For PFES, we partition the dominated space under each sampled Pareto frontier using the algorithm proposed Lacour et al. [34], which is more efﬁcient and yields fewer hyperrectangles than the Quick Hypervolume algorithm used by the PFES authors [51]. For qNParEGO, we use a similar pruning strategy to that in qNEHVI to only integrate over the function values of in-sample points that have positive probability of being best with respect to the sampled scalarization. We use the off-the-shelf implementation of qNParEGO in BoTorch [2], which does not use low-rank Cholesky updates; however, we do note thatqNPAREGO would likely achieve lower wall times using more efﬁcient linear algebra tricks. For DGEMO, TSEMO, and MOEA/D-EGO, we use the default settings provided in https:// github.com/yunshengtian/DGEMO/tree/master. G.3 Problem Details All benchmark problems are treated as maximization problems; the objectives for minimization problems are multiplied by -1 to obtain an equivalent maximization problem. 9More efﬁcient methods for this step exist (e.g. Dächert et al. [15]), but Klamroth et al. [31] can easily leverage vectorized operations and we ﬁnd it to be efﬁcient in our experiments. 21BraninCurrin (M = 2, d= 2) The BraninCurrin problem involves optimizing two competing functions used in BO benchmarks: Branin and Currin. The goal is minimize both: f(1)(x′ 1,x′ 2) = (x2 −5.1 4π2 x2 1 + 5 πx1 −r)2 + 10(1 − 1 8π) cos(x1) + 10 f(2)(x1,x2) = [ 1 −exp ( − 1 (2x2) )]2300x3 1 + 1900x2 1 + 2092x1 + 60 100x3 1 + 500x2 1 + 4x1 + 20 where x1,x2 ∈[0,1], x′ 1 = 15x1 −5, and x′ 2 = 15x2. DTLZ2 (M = 2,d = 6) DTLZ2 [13] is a standard problem from the multi-objective optimization literature. The two objectives are f1(x) = (1 + g(xM)) cos (π 2 x1 ) ···cos (π 2 xM−2 ) cos (π 2 xM−1 ) f2(x) = (1 + g(xM)) cos (π 2 x1 ) ···cos (π 2 xM−2 ) sin (π 2 xM−1 ) , where g(x) = ∑ xi∈xM (xi −0.5)2,x∈[0,1]d,and xM is the d−M + 1 elements of x. ZDT1 (M = 2, d= 4) ZDT1 is a benchmark problem from the multi-objective optimization literature [66]. The goal is minimize the following two objectives f(1)(x) = x1 f(2)(x) = g(x) ( 1 − √ f(1)(x) g(x) ) where g(x) = 1 + 9 d−1 ∑d i=2 xi and x= [x1,...,x d] ∈[0,1]d. VehicleSafety (M = 3, d= 5) The 3 objectives are based on a response surface model that is ﬁt to data collected from a simulator and are given by [53]: f1(x) = 1640.2823 + 2.3573285x1 + 2.3220035x2 + 4.5688768x3 + 7.7213633x4 + 4.4559504x5 f2(x) = 6.5856 + 1.15x1 −1.0427x2 + 0.9738x3 + 0.8364x4 −0.3695x1x4 + 0.0861x1x5 + 0.3628x2x4 + 0.1106x2 1 −0.3437x2 3 + 0.1764x2 4 f3(x) = −0.0551 + 0.0181x1 + 0.1024x2 + 0.0421x3 −0.0073x1x2 + 0.024x2x3 −0.0118x2x4 −0.0204x3x4 −0.008x3x5 −0.0241x2 2 + 0.0109x2 4 where x ∈ [1,3]5. We seek to (1) minimize mass (a proxy for fuel efﬁciency), (2) minimize acceleration (a proxy for passenger trauma) in a full-frontal collision, and (3) minimize the distance that the toe-board intrudes into the cabin (a proxy for vehicle fragility) [53]. AutoML (M = 2, d= 8) . This experiment considers optimizing predictive performance and latency of a deep neural networks (DNN). Practitioners and researchers across many domains use DNNs for recommendation and recognition tasks in low-latency (e.g. on-device) environments [49], where any increase in prediction time degrades the product experience [43]. Simultaneously, researchers are considering increasingly larger architectures that improve predictive performance [48]. Therefore, a ﬁrm may be interesting understanding the set of optimal trade-offs between prediction latency and predictive performance. For a demonstration, we consider optimizing (d= 8) hyperparameters of DNN (detailed in Table 1) to minimize out-of-sample prediction error and minimize latency on the MNIST data set [ 35]. Using a small randomized test set leads to noisy evaluations of predictive performance and latency measurements are often noisy due to unrelated ﬂuctuations in the testing environment. As in previous works, we minimize a logit transformation of the prediction error and minimize a logarithm of the ratio between the latency of a proposed DNN and the latency of the fastest DNN [20, 21, 25]. For each evaluation, we randomly partition the 60,000 examples from the MNIST training set into a set of 50,000 examples for training and 10,000 examples for evaluation. We train each network for 8 epochs using SGD with momentum with mini-batches of 512 examples. The learning rate is decayed after every 30 mini-batch updates using the speciﬁed 22PARAMETER SEARCH SPACE LEARNING RATE (log10 SCALE ) [-5.0, -1.0] LEARNING RATE DECAY MULTIPLIER [0.01, 1.0] DROPOUT RATE [0.0, 0.7] L1 REGULARIZATION [10−5, 0.1] L2 REGULARIZATION [10−5, 0.1] HIDDEN LAYER 1 SIZE [20, 500] HIDDEN LAYER 2 SIZE [20, 500] HIDDEN LAYER 3 SIZE [20, 500] Table 1: The search space for the AutoML benchmark. decay multiplier. We use randomized rounding on the integer parameters before evaluation. For evaluating the performance of different BO methods, we estimate the noiseless objectives using the mean objectives across 3 replications. DNNs are implemented in PyTorch using ReLU activations and a softmax output layer. Latency measurements are taken on a CPU (2x Intel Xeon E5-2680 v4 @ 2.40GHz). CarSideImpact ( M = 4, d= 7) A side-impact test is common practice under European Enhanced Vehicle-Safety Committee to uphold vehicle safety standards [14]. In constrast with the previous VehicleSafety problem where we considered a full-frontal collision, we now consider the problem of tuning parameters controlling the structural design the of an automobile in the case of a side-impact collision. This problem has been widely used in various works and has previously used stochastic parameters to account for manufacturing error [14]. We use the recent 4-objective version proposed by Tanabe & Ishibuchi[53] where the goal to minimize the weight of the vehicle, passenger trauma (pubic force), and vehicle damage (the average velocity of the V-pillar). The fourth objective is a combination of 10 other measures of the vehicle durability and passenger safety (see [14] for details). The mathematical formulas for a response surface model ﬁt to data collected from a simulator are given below: f(1)(x) = 1.98 + 4.9x1 + 6.67x2 + 6.98x3 + 4.01x4 + 1.78x5 + 10−5x6 + 2.73x7 f(2)(x) = 4.72 −0.5x4 −0.19x2x3 f(3)(x) = 0.5(VMBP(x) + VFD(x)) f(4)(x) = − 10∑ i=1 max[gi(x),0] where g1(x) = 1 −1.16 + 0.3717x2x4 + 0.0092928x3 g2(x) = 0.32 −0.261 + 0.0159x1x2 + 0.06486x1 + 0.019x2x7 −0.0144x3x5 −0.0154464x6 g3(x) = 0.32 −0.214 −0.00817x5 + 0.045195x1 + 0.0135168x1 −0.03099x2x6 + 0.018x2x7 −0.007176x3 −0.023232x3 + 0.00364x5x6 + 0.018x2 2 g4(x) = 0.32 −0.74 + 0.61x2 + 0.031296x3 + 0.031872x7 −0.227x2 2 g5(x) = 32 −28.98 −3.818x3 + 4.2x1x2 −1.27296x6 + 2.68065x7 g6(x) = 32 −33.86 −2.95x3 + 5.057x1x2 + 3.795x2 + 3.4431x7 −1.45728 g7(x) = 32 −46.36 + 9.9x2 + 4.4505x1 g8(x) = 4 −f2(x) g9(x) = 9.9 −VMBP(x) g10(x) = 15.7 −VFD(x) VMBP(x) = 10.58 −0.674x1x2 −0.67275x2 VFD(x) = 16.45 −0.489x3x7 −0.843x5x6 23. The search space is: x1 ∈[0.5,1.5] x2 ∈[0.45,1.35] x3,x4 ∈[0.5,1.5] x5 ∈[0.875,2.625] x6,x7 ∈[0.4,1.2]. As in the VehicleSafety problem, we add zero-mean Gaussian noise to each objective with a standard deviation of 1% the range of each objective. Constrained BraninCurrin (M = 2, V= 2, d= 2) The constrained BraninCurrin problem uses the same objectives as BraninCurrin, but adds the following disk constraint from [22]: c(x′ 1,x′ 2) = 50 −(x′ 1 −2.5)2 −(x′ 2 −7.5)2) ≥0 We add zero-mean Gaussian noise to objectives and the constraint slack observations with a standard deviation of 5% of the range of each outcome. SphereEllipsoidal (M = 2, d= 5) The SphereEllipsoidal problem is deﬁned over x∈[−5,5]d and the objectives are given by [6]: f(1)(x) = d∑ i=1 (xi −x(1) opt,i)2 + f(1) opt f(2)(x) = d∑ i=1 106 i−1 d−1 z2 i + f(2) opt where zi = Tosz(δi) δi = xi −x(2) opt,i Tosz(δi) = sign(δi)e ˆδi+0.049 ( sin [ c1(δi) ˆδi ] +sin [ c2(δi) ˆδi ]) and ˆδi = {log(|δi|), if δi ̸= 0 0, otherwise c1(δi) = {10, if δi ≥0 5.5, otherwise c2(δi) = {7.9, if δi ≥0 3.1, otherwise. We set x(1) opt = [−0.0299,2.1458,−3.2922,−2.9438,−1.5406] x(2) opt = [2.0611,−1.7655,−0.7754,1.8775,−3.7657] f(1) opt = 203.71 f(2) opt = 135.6 . We add zero-mean Gaussian noise to objectives and the constraint slack observations with a standard deviation of 5% of the range of each outcome. 24PROBLEM REFERENCE POINT BRANIN CURRIN [-18.00, -6.00] ZDT1 [-1.10, -1.10] DTLZ2 [−1.10]M VEHICLE SAFETY [-1698.55, -11.21, -0.29] ABR [150.00, -3500.00] AUTO ML [-2.45, 0.60] CARSIDE IMPACT [-45.49, -4.51, -13.34, -10.39] CONSTRAINED BRANIN CURRIN [-80.00, -12.00] SPHERE ELLIPSOIDAL [-261.00, −6.77 ·106] Table 2: The reference points for each benchmark problem. G.4 Evaluation Details To compute the log hypervolume difference metric, we use NSGA-II to estimate the true Pareto frontier (except for the ABR and AutoML problems, where evaluations are time-consuming and we instead take the true Pareto frontier to be the Pareto frontier across the estimated objectives across all methods and replications). Using this Pareto frontier, we compute the hypervolume dominated by the true Pareto frontier in order to calculate the log hypervolume difference. For ZDT1, the hypervolume dominated by the true Pareto frontier can be computed analytically. For Constrained BraninCurrin, we evaluate the logarithm of the difference between the hypervolume dominated by the true feasible Pareto frontier and the feasible in-sample Pareto frontier for each method. For all problems, we selected the reference point based on the component-wise noiseless nadir point fnadir(x) = min x∈Xf(x) and the range of the Pareto frontier for each noiseless objective using the common heuristic [56]: r= fnadir(x) −β∗(fideal(x) −fnadir(x)),where β = 0.1 and fideal(x) = maxx∈Xf(x). H Experiments H.1 Wall Time Results Tables 3 and 4 report the acquisition optimization wall times for each method. On all benchmark problems except CarSideImpact, qNEHVI is faster to optimize than MESMO and PFES on a GPU. The wall times for optimizingqNEHVI are competitive with those forqNParEGO on most benchmark problems and batch sizes; on many problems, qNEHVI is often faster than qNParEGO. On the problems VehicleSafety and CarSideImpact problems which have 3 and 4 objectives respectively, we observed tractable wall times, even when generating q= 32 candidates. The wall time for 3 and 4 objective problems is larger primarily because the box decompositions are more time-consuming to compute and result in more hyperrectangles as the number of objectives increases. Although, qEHVI (-PM) is faster for q = 1 and q = 8 on many problems, it is unable to scale to large batch sizes and ran out of memory for q = 8 on CarSideImpact due to the box decomposition having a large number of hyperrectangles. 25CPU BRANINCURRIN ZDT1 ABR V EHICLE SAFETY MESMO (q=1) 21.24 (±0.02) 19 .76 (±0.03) 23 .24 (±0.04) 28 .39 (±0.07) PFES (q=1) 22.86 (±0.05) 39 .82 (±0.14) 43 .03 (±0.12) 53 .16 (±0.17) TS-TCH (q=1) 0.51 (±0.0) 0 .48 (±0.0) 0 .75 (±0.0) 0 .67 (±0.0) qEHVI-PM-CBD ( q=1) 2.34 (±0.02) 3 .7 (±0.02) 3 .56 (±0.03) 7 .82 (±0.05) qEHVI (q=1) 0.58 (±0.0) 0 .66 (±0.01) 2 .98 (±0.02) 5 .07 (±0.03) qNEHVI (q=1) 40.55 (±0.61) 35 .66 (±0.47) 62 .29 (±0.97) 120 .43 (±1.25) qNPAREGO (q=1) 3.19 (±0.05) 1 .65 (±0.02) 6 .94 (±0.06) 1 .05 (±0.01) qPAREGO (q=1) 0.58 (±0.01) 0 .7 (±0.01) 2 .5 (±0.03) 0 .75 (±0.01) DGEMO (q=1) 65.28(±0.26) 76 .99(±0.35) NA NA DGEMO (q=8) 65.44(±0.63) 86 .97(±0.85) NA NA DGEMO (q=16) 66.44(±0.93) 86 .06(±1.21) NA NA DGEMO (q=32) 66.66(±1.47) 84 .66(±1.66) NA NA TSEMO (q=1) 3.02(±0.01) 2 .98(±0.01) NA 3.61(±0.01) TSEMO (q=8) 3.53(±0.01) 3 .48(±0.01) NA 7.45(±0.1) TSEMO (q=16) 3.77(±0.02) 3 .74(±0.02) NA 11.06(±0.28) TSEMO (q=32) 4.29(±0.03) 4 .22(±0.02) NA 16.3(±0.68) MOEA/D-EGO (q=1) 57.79(±0.17) 58 .1(±0.17) NA 71.0(±0.21) MOEA/D-EGO (q=8) 63.56(±0.18) 63 .57(±0.17) NA 77.56(±0.22) MOEA/D-EGO (q=16) 64.0(±0.18) 63 .99(±0.19) NA 78.03(±0.25) MOEA/D-EGO (q=32) 64.09(±0.26) 63 .9(±0.24) NA 77.77(±0.35) GPU BRANINCURRIN ZDT1 ABR VEHICLE SAFETY MESMO (q=1) 19.9 (±0.04) 19 .92 (±0.04) 21 .54 (±0.08) 24 .57 (±0.09) PFES (q=1) 21.68 (±0.07) 45 .9 (±0.17) 43 .3 (±0.13) 47 .25 (±0.16) TS-TCH (q=1) 0.88 (±0.01) 0 .94 (±0.01) 1 .08 (±0.01) 1 .04 (±0.01) TS-TCH (q=8) 1.85 (±0.03) 2 .01 (±0.03) 2 .99 (±0.04) 2 .32 (±0.05) TS-TCH (q=16) 3.08 (±0.08) 3 .29 (±0.1) 4 .28 (±0.08) 3 .54 (±0.09) TS-TCH (q=32) 5.25 (±0.15) 5 .41 (±0.16) 7 .23 (±0.2) 6 .41 (±0.23) qEHVI-PM-CBD ( q=1) 2.17(±0.01) 2 .12(±0.02) 3 .59(±0.02) 51 .11(±0.28) qEHVI-PM-CBD ( q=8) 39.56(±0.79) 30 .83(±1.35) 36 .2(±0.73) 716 .03(±13.44) qEHVI-PM-CBD ( q=16) 82.91(±2.42) 67 .3(±3.88) 70 .02(±1.64) 1410 .79(±41.72) qEHVI-PM-CBD ( q=32) 147.81(±6.85) 105 .74(±8.55) 251 .97(±12.69) 2570 .95(±116.61) qEHVI (q=1) 0.72 (±0.01) 0 .99 (±0.02) 3 .67 (±0.02) 3 .96 (±0.05) qEHVI (q=8) 18.12 (±1.03) 18 .05 (±0.86) 40 .55 (±0.58) 71 .49 (±2.04) qNEHVI (q=1) 6.15 (±0.06) 5 .75 (±0.04) 7 .72 (±0.09) 20 .81 (±0.11) qNEHVI (q=8) 48.19 (±1.2) 46 .74 (±0.83) 49 .7 (±0.79) 168 .63 (±2.49) qNEHVI (q=16) 102.87 (±4.02) 95 .6 (±2.62) 93 .14 (±1.72) 289 .02 (±5.82) qNEHVI (q=32) 177.56 (±7.81) 190 .59 (±6.07) 181 .97 (±4.77) 546 .83 (±16.09) qNEHVI-1 (q=1) 0.32(±0.0) 0 .24(±0.0) 0 .56(±0.0) 0 .92(±0.0) qNEHVI-1 (q=8) 2.43(±0.02) 2 .11(±0.03) 4 .55(±0.06) 7 .1(±0.1) qNEHVI-1 (q=16) 4.97(±0.07) 3 .73(±0.06) 8 .73(±0.14) 14 .77(±0.31) qNEHVI-1 (q=32) 9.03(±0.18) 8 .18(±0.24) 17 .15(±0.41) 34 .99(±1.46) qNPAREGO (q=1) 2.39 (±0.04) 1 .84 (±0.04) 6 .47 (±0.05) 0 .9 (±0.02) qNPAREGO (q=8) 47.05 (±1.74) 52 .99 (±1.94) 74 .72 (±1.9) 45 .56 (±1.17) qNPAREGO (q=16) 118.73 (±5.53) 116 .68 (±5.51) 116 .79 (±3.19) 91 .3 (±3.83) qNPAREGO (q=32) 306.17 (±17.81) 279 .01 (±17.72) 240 .56 (±6.44) 188 .42 (±13.42) qPAREGO (q=1) 0.81 (±0.02) 1 .05 (±0.03) 4 .39 (±0.05) 0 .79 (±0.02) qPAREGO (q=8) 13.01 (±0.53) 16 .4 (±0.72) 31 .02 (±0.81) 12 .64 (±0.84) qPAREGO (q=16) 34.34 (±2.12) 43 .66 (±3.12) 66 .85 (±3.13) 36 .68 (±4.48) qPAREGO (q=32) 139.73 (±25.22) 108 .25 (±6.94) 122 .37 (±6.12) 107 .34 (±14.76) Table 3: Acquisition function optimization wall time (including box decompositions) in seconds on a CPU (2x Intel Xeon E5-2680 v4 @ 2.40GHz) and a Tesla V100 SXM2 GPU (16GB RAM). The mean and two standard errors are reported. DGEMO, TSEMO, and MOEA/D-EGO are omitted for ABR because they have package requirements that are not easily compatible with our distributed evaluation pipeline and ABR evaluations are prohibitively slow without distributed evaluations. DGEMO is omitted for VehicleSafety because the open-source implementation raises an consistently raises an exception in the graph cutting algorithm with this problem. 26H.2 Scaling to large batch sizes with CBD In Figure 6, we provide results demonstrating the CBD approach enables scaling to large batch sizes, even with 3 or 4 objectives, whereas the IEP wall times grow exponentially with the batch size and the IEP overﬂows GPU memory even with modest batch sizes. 0 25 50 75 100 q 0 200 400 600 800Acquisition Optimization Time (s) 3 Objectives CBD (CPU) CBD (GPU) IEP (CPU) IEP (GPU) OOM 0 25 50 75 100 q 0 500 1000 1500 2000 4 Objectives Figure 6: Acquisition optimization wall time under a sequential greedy approximation using L- BFGS-B for three and four objectives. CBD enables scaling to much larger batch sizes q than using the inclusion-exclusion principle (IEP) and avoids running out-of-memory (OOM) on a GPU. Independent GPs are used for each outcome and are initialized with 20 points from the Pareto frontier of the 6-dimensional DTLZ2 problem [13] with 3 objectives (left) and 4 objectives (right). Wall times were measured on a Tesla V100 SXM2 GPU (16GB GPU RAM) and a Intel Xeon Gold 6138 CPU @ 2GHz CPU (251GB RAM). H.3 Additional Empirical Results The additional optimization performance results in the appendix demonstrate that qNEHVI -based algorithms are consistently the top performer. The only case where qNEHVI (-1) is outperformed is in the sequential setting on the CarSideImpact problem in Figure 9(a), where qEHVI performs best However, as show in Figure 9(b) and Figure 9(c), qNEHVI enables scaling to large batch sizes, whereas qEHVI runs out of memory on a GPU for q = 8. Therefore, in a practical setting where vehicles are manufactured and test in parallel, qNEHVI would be the best choice. Figure 11 shows that qNEHVI achieves solid performance anytime throughout the learning curve in the sequential setting, and Figure 13 shows that qNEHVI -based variants consistently achieves the best performance for variousqwith a ﬁxed budget of 224 function evaluations. Although,qNEHVI-1 does not consistently perform better than qNEHVI , qNEHVI-1 achieves very little degradation of sample complexity as the batch size qincreases. H.4 Better performance from qEHVI with a larger batch size Interestingly, on many test problems qEHVI performs better with q = 8 than q = 1 . In the case of BraninCurrin and ConstrainedBraninCurrin, qParEGO also improves as qincreases. Since this phenomenon is not observed with the noisy acquisition functions (qNEHVI , qNParEGO), we hypothesize that it may be the case that sequential data collection results in a difﬁcult to optimize acquisition surface and that integrating over the in-sample points leads to a smoother acquisition surface that results in improved sequential optimization. The acquisition functions that do not account for noise may be misled by the noise in sequential setting, but using a larger batch size (within limits) may help avoid the issue of not properly accounting for noise. 27H.5 Performance over Higher Dimensional Spaces qNEHVI-1 relies on approximate GP sample paths (RFFs). Although we ﬁnd that qNEHVI-1 performs very well on many low-dimensional problems (see Figure 4), Figures 8 and 7 show that qNEHVI-1 does not perform as well a qNEHVI on higher dimensional problems. We hypothesize that the RFF approximation degrades in higher dimensional search spaces leading to poor optimization performance relative qNEHVI , which uses exact GP samples. It is likely that using 500 Fourier basis functions leads to large approximation error on high dimensional search spaces. Further study is needed to examine whether robust performance can be achieved by increasing the number of basis functions. As shown in Figure 7, qNEHVI consistently outperforms all tested methods regardless of the dimension of the design space. 0 50 100 150 200 Function Evaluations 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40Hypervolume d=5 qNEHVI qNParEGO TS-TCH qNEHVI-1 0 50 100 150 200 Function Evaluations d=10 0 50 100 150 200 Function Evaluations d=15 0 50 100 150 200 Function Evaluations d=20 Figure 7: Sequential optimization performance 2-objective DTLZ2 with σ = 5% problems as the dimension of the search space increases from d= 5 to d= 20. 1 8 16 32 q -1.25 -1.20 -1.15 -1.10 -1.05 -1.00 -0.95 -0.90 -0.85Log Hypervolume Difference d=5 1 8 16 32 q -0.75 -0.72 -0.70 -0.68 -0.65 -0.62 -0.60 -0.57 -0.55 d=10 1 8 16 32 q -0.54 -0.52 -0.50 -0.48 -0.46 -0.44 -0.42 -0.40 -0.38 d=15 1 8 16 32 q -0.42 -0.41 -0.40 -0.39 -0.38 -0.37 d=20 qNEHVI qNEHVI-1 Figure 8: A comparison of the ﬁnal optimization performance of qNEHVI-1 , a single sample path approximation of qNEHVI , and qNEHVI on 2-objective DTLZ2 problems with input dimensions between 5 and 20 under different batch sizes q. qNEHVI-1 is very effective on lower dimensional problems, but does not perform as well as qNEHVI on higher dimensional problems. 28CPU DTLZ2 A UTOML C ARSIDEIMPACT CONSTRAINEDBRANINCURRIN MESMO (q=1) 27.79(±0.07) 37 .86 (±0.08) 33 .31 (±0.06) NA PFES (q=1) 69.85(±0.21) 101 .24 (±0.29) 102 .55 (±0.34) NA TS-TCH (q=1) 0.72(±0.0) 0 .93 (±0.0) 1 .27 (±0.01) NA qEHVI-PM-CBD (q=1) 3.98(±0.02) 5 .76 (±0.05) 83 .14 (±0.74) 10 .27 (±0.06) qEHVI (q=1) 2.74(±0.01) 5 .05 (±0.04) 96 .19 (±0.9) 3 .26 (±0.05) qNEHVI (q=1) 54.04(±0.67) 22 .71 (±0.48) 541 .13 (±6.83) 267 .67 (±4.09) qNPAREGO (q=1) 21.39(±0.2) 5 .6 (±0.07) 3 .38 (±0.05) 12 .05 (±0.17) qPAREGO (q=1) 2.33(±0.02) 3 .06 (±0.03) 1 .91 (±0.02) 1.56 (±0.03) DGEMO (q=1) 84.48(±0.64) NA NA NA DGEMO (q=8) 65.99(±0.51) NA NA NA DGEMO (q=16) 69.57(±0.59) NA NA NA DGEMO (q=32) 72.82(±0.8) NA NA NA TSEMO (q=1) 3.1(±0.01) NA 14.91(±0.16) NA TSEMO (q=8) 3.58(±0.01) NA 100.78(±3.75) NA TSEMO (q=16) 3.87(±0.02) NA 188.44(±9.88) NA TSEMO (q=32) 4.55(±0.03) NA 326.51(±24.03) NA MOEA/D-EGO (q=1) 59.3(±0.18) NA 79.87(±0.16) NA MOEA/D-EGO (q=8) 65.5(±0.18) NA 85.34(±0.21) NA MOEA/D-EGO (q=16) 65.81(±0.2) NA 85.18(±0.3) NA MOEA/D-EGO (q=32) 65.44(±0.3) NA 84.8(±0.39) NA GPU DTLZ2 A UTOML C ARSIDEIMPACT CONSTRAINEDBRANINCURRIN MESMO (q=1) 17.01(±0.13) 28 .83 (±0.2) 26 .0 (±0.06) NA PFES (q=1) 46.63(±0.51) 85 .73 (±0.4) 55 .41 (±0.16) NA TS-TCH (q=1) 0.84(±0.01) 1 .49 (±0.01) 2 .17 (±0.01) NA TS-TCH (q=8) 3.71(±0.07) 3 .64 (±0.1) 4 .15 (±0.07) NA TS-TCH (q=16) 5.85(±0.14) 6 .16 (±0.21) 6 .9 (±0.19) NA TS-TCH (q=32) 9.33(±0.3) 9 .47 (±0.47) 10 .2 (±0.4) NA qEHVI-PM-CBD (q=1) 4.29(±0.01) 5 .26(±0.05) 52 .7(±0.41) 15 .89(±0.08) qEHVI-PM-CBD (q=8) 40.85(±0.41) 39 .55(±0.8) 460 .18(±9.76) 135 .89(±1.43) qEHVI-PM-CBD (q=16) 93.39(±1.87) 71 .8(±1.81) 866 .12(±26.46) 314 .42(±5.44) qEHVI-PM-CBD (q=32) 194.12(±5.6) 143 .83(±4.88) 1682 .28(±72.5) 823 .01(±24.48) qEHVI (q=1) 2.93(±0.02) 4 .67 (±0.1) 9 .63 (±0.05) 5 .69 (±0.11) qEHVI (q=8) 39.64(±0.57) 104 .48 (±1.34) OOM 68.95 (±2.57) qNEHVI (q=1) 4.91(±0.01) 7 .95 (±0.1) 82 .66 (±0.63) 20 .47 (±0.12) qNEHVI (q=8) 39.96(±0.35) 67 .28 (±1.87) 683 .06 (±13.82) 168 .04 (±1.85) qNEHVI (q=16) 74.41(±0.63) 145 .66 (±4.45) 1289 .4 (±36.81) 362 .15 (±9.08) qNEHVI (q=32) 142.18(±1.59) 247.92 (±11.93) 2480.41 (±102.38) 654 .66 (±23.48) qNEHVI-1 (q=1) 0.42(±0.0) 0 .53(±0.0) 2 .11(±0.01) 1 .57(±0.02) qNEHVI-1 (q=8) 3.26(±0.03) 4 .55(±0.09) 16 .88(±0.2) 11 .01(±0.16) qNEHVI-1 (q=16) 6.34(±0.04) 7 .22(±0.19) 34 .78(±0.63) 20 .56(±0.4) qNEHVI-1 (q=32) 14.85(±0.45) 12 .66(±0.54) 67 .27(±1.61) 40 .6(±1.1) qNPAREGO (q=1) 6.41(±0.03) 4 .86 (±0.1) 3 .25 (±0.06) 6 .17 (±0.07) qNPAREGO (q=8) 57.17(±0.43) 48 .62 (±1.18) 30 .65 (±0.92) 38 .66 (±0.95) qNPAREGO (q=16) 114.91(±1.3) 122 .09 (±3.5) 81 .04 (±3.44) 84 .27 (±3.04) qNPAREGO (q=32) 263.56(±4.03) 275 .41 (±8.29) 219 .98 (±9.75) 199 .6 (±9.68) qPAREGO (q=1) 2.62(±0.03) 3 .31 (±0.07) 3 .03 (±0.06) 2 .83 (±0.08) qPAREGO (q=8) 25.75(±0.66) 33 .84 (±1.76) 22 .0 (±0.88) 20 .28 (±1.18) qPAREGO (q=16) 67.89(±2.27) 77 .25 (±3.9) 56 .09 (±3.09) 50 .06 (±3.84) qPAREGO (q=32) 159.98(±7.41) 217.55 (±19.15) 139 .25 (±9.41) 135 .39 (±13.04) Table 4: Acquisition function optimization wall time (including box decompositions) in seconds on a CPU (2x Intel Xeon E5-2680 v4 @ 2.40GHz) and a Tesla V100 SXM2 GPU (16GB RAM). The mean and two standard errors are reported. DGEMO, TSEMO, MOEA/D-EGO are omitted for AutoML because they have package requirements that are not easily compatible with our distributed training and evaluation pipeline, and they are omitted for ConstrainedBraninCurrin because they do not support constraints in the open-source implementation at https://github.com/yunshengtian/DGEMO/ tree/master. DGEMO is omitted on CarSideImpact because the open-source implementation does not support more than 3 objectives. 290 50 100 150 200 Function Evaluations -0.20 -0.10 0.00 0.10 0.20 Log Hypervolume Difference AutoML 0 50 100 150 200 Function Evaluations 1.20 1.40 1.60 1.80 2.00 2.20 2.40 CarSideImpact 0 50 100 150 200 Function Evaluations 1.00 1.20 1.40 1.60 1.80 2.00 2.20 2.40 ConstrainedBraninCurrin 0 50 100 150 200 Function Evaluations -2.00 -1.50 -1.00 -0.50 0.00 ZDT1 DGEMO MESMO MOEA/D-EGO PESMO PFES TS-TCH TSEMO qEHVI qEHVI-PM-CBD qNEHVI qNEHVI-1 qNParEGO (a) Sequential Optimization performance on additional benchmark problems. 0 50 100 150 200 Batch Iteration 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75Log Hypervolume Difference BraninCurrin 0 50 100 150 200 Batch Iteration -1.10 -1.00 -0.90 -0.80 -0.70 -0.60 -0.50 DTLZ2 0 50 100 150 200 Batch Iteration -0.50 0.00 0.50 1.00 VehicleSafety 0 50 100 150 200 Batch Iteration 4.80 5.00 5.20 5.40 5.60 5.80 ABR DGEMO (q=1) DGEMO (q=16) DGEMO (q=32) DGEMO (q=8) MOEA/D-EGO (q=1) MOEA/D-EGO (q=16) MOEA/D-EGO (q=32) MOEA/D-EGO (q=8) TS-TCH (q=1) TS-TCH (q=16) TS-TCH (q=32) TS-TCH (q=8) TSEMO (q=1) TSEMO (q=16) TSEMO (q=32) TSEMO (q=8) qNEHVI (q=1) qNEHVI (q=16) qNEHVI (q=32) qNEHVI (q=8) qNParEGO (q=1) qNParEGO (q=16) qNParEGO (q=32) qNParEGO (q=8) (b) Parallel optimization performance vs batch iterations (1/2). 0 50 100 150 200 Batch Iteration -0.20 -0.10 0.00 0.10 0.20 Log Hypervolume Difference AutoML 0 50 100 150 200 Batch Iteration 1.40 1.60 1.80 2.00 2.20 2.40 CarSideImpact 0 50 100 150 200 Batch Iteration 1.00 1.20 1.40 1.60 1.80 2.00 2.20 2.40 ConstrainedBraninCurrin 0 50 100 150 200 Batch Iteration -2.00 -1.75 -1.50 -1.25 -1.00 -0.75 -0.50 -0.25 0.00 ZDT1 DGEMO (q=1) DGEMO (q=16) DGEMO (q=32) DGEMO (q=8) MOEA/D-EGO (q=1) MOEA/D-EGO (q=16) MOEA/D-EGO (q=32) MOEA/D-EGO (q=8) TS-TCH (q=1) TS-TCH (q=16) TS-TCH (q=32) TS-TCH (q=8) TSEMO (q=1) TSEMO (q=16) TSEMO (q=32) TSEMO (q=8) qNEHVI (q=1) qNEHVI (q=16) qNEHVI (q=32) qNEHVI (q=8) qNParEGO (q=1) qNParEGO (q=16) qNParEGO (q=32) qNParEGO (q=8) (c) Parallel optimization performance vs batch iterations (2/2). Figure 9: Optimization performance on additional problems. (a) Sequential optimization performance. (b) and (c) Optimization performance of batch acquisition functions using various qover the number of BO iterations. To improve readability, we omitqEHVI (-PM) in this ﬁgure because the IEP cannot scale beyond q= 8 because of the exponential time and space complexity (running it on a GPU runs out of memory and running it on a CPU results in prohibitively slow wall times). See Figure 10 for results using qEHVI(-PM). 300 50 100 150 200 Batch Iteration -0.25 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 Log Hypervolume Difference BraninCurrin 0 50 100 150 200 Batch Iteration -1.10 -1.00 -0.90 -0.80 -0.70 -0.60 -0.50 DTLZ2 0 50 100 150 200 Batch Iteration -1.00 -0.50 0.00 0.50 1.00 VehicleSafety 0 50 100 150 200 Batch Iteration 4.80 5.00 5.20 5.40 5.60 5.80 ABR qEHVI-PM-CBD (q=1) qEHVI-PM-CBD (q=8) qNEHVI (q=1) qNEHVI (q=16) qNEHVI (q=32) qNEHVI (q=8) qNEHVI-1 (q=1) qNEHVI-1 (q=16) qNEHVI-1 (q=32) qNEHVI-1 (q=8) (a) 0 50 100 150 200 Batch Iteration -0.20 -0.10 0.00 0.10 0.20 Log Hypervolume Difference AutoML 0 50 100 150 200 Batch Iteration 1.40 1.60 1.80 2.00 2.20 2.40 CarSideImpact 0 50 100 150 200 Batch Iteration 1.00 1.20 1.40 1.60 1.80 2.00 2.20 2.40 ConstrainedBraninCurrin 0 50 100 150 200 Batch Iteration -2.00 -1.50 -1.00 -0.50 0.00 ZDT1 qEHVI-PM-CBD (q=1) qEHVI-PM-CBD (q=16) qEHVI-PM-CBD (q=32) qEHVI-PM-CBD (q=8) qNEHVI (q=1) qNEHVI (q=16) qNEHVI (q=32) qNEHVI (q=8) qNEHVI-1 (q=1) qNEHVI-1 (q=16) qNEHVI-1 (q=32) qNEHVI-1 (q=8) (b) Figure 10: Optimization performance of qNEHVI under various batch sizes qvs qEHVI (-PM ). Note that using the IEP , qEHVI (-PM ) cannot scale beyond q= 8 because of the exponential time and space complexity (running it on a GPU runs out of memory and running it on a CPU results in prohibitively slow wall times). 310 50 100 150 200 Function Evaluations 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75Log Hypervolume Difference BraninCurrin 0 50 100 150 200 Function Evaluations -1.10 -1.00 -0.90 -0.80 -0.70 -0.60 -0.50 DTLZ2 0 50 100 150 200 Function Evaluations -0.50 0.00 0.50 1.00 VehicleSafety 0 50 100 150 200 Function Evaluations 4.80 5.00 5.20 5.40 5.60 5.80 ABR DGEMO (q=1) DGEMO (q=16) DGEMO (q=32) DGEMO (q=8) MOEA/D-EGO (q=1) MOEA/D-EGO (q=16) MOEA/D-EGO (q=32) MOEA/D-EGO (q=8) TS-TCH (q=1) TS-TCH (q=16) TS-TCH (q=32) TS-TCH (q=8) TSEMO (q=1) TSEMO (q=16) TSEMO (q=32) TSEMO (q=8) qNEHVI (q=1) qNEHVI (q=16) qNEHVI (q=32) qNEHVI (q=8) qNParEGO (q=1) qNParEGO (q=16) qNParEGO (q=32) qNParEGO (q=8) (a) 0 50 100 150 200 Function Evaluations -0.20 -0.10 0.00 0.10 0.20 Log Hypervolume Difference AutoML 0 50 100 150 200 Function Evaluations 1.40 1.60 1.80 2.00 2.20 2.40 CarSideImpact 0 50 100 150 200 Function Evaluations 1.00 1.20 1.40 1.60 1.80 2.00 2.20 2.40 ConstrainedBraninCurrin 0 50 100 150 200 Function Evaluations -2.00 -1.75 -1.50 -1.25 -1.00 -0.75 -0.50 -0.25 0.00 ZDT1 DGEMO (q=1) DGEMO (q=16) DGEMO (q=32) DGEMO (q=8) MOEA/D-EGO (q=1) MOEA/D-EGO (q=16) MOEA/D-EGO (q=32) MOEA/D-EGO (q=8) TS-TCH (q=1) TS-TCH (q=16) TS-TCH (q=32) TS-TCH (q=8) TSEMO (q=1) TSEMO (q=16) TSEMO (q=32) TSEMO (q=8) qNEHVI (q=1) qNEHVI (q=16) qNEHVI (q=32) qNEHVI (q=8) qNParEGO (q=1) qNParEGO (q=16) qNParEGO (q=32) qNParEGO (q=8) (b) Figure 11: Anytime optimization performance of batch acquisition functions using various qover the number of function evaluations. To improve readability, we omit qEHVI (-PM) in this ﬁgure because the IEP cannot scale beyond q= 8 because of the exponential time and space complexity (running it on a GPU runs out of memory and running it on a CPU results in prohibitively slow wall times). 320 50 100 150 200 Function Evaluations -0.25 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 Log Hypervolume Difference BraninCurrin 0 50 100 150 200 Function Evaluations -1.10 -1.00 -0.90 -0.80 -0.70 -0.60 -0.50 DTLZ2 0 50 100 150 200 Function Evaluations -1.00 -0.50 0.00 0.50 1.00 VehicleSafety 0 50 100 150 200 Function Evaluations 4.80 5.00 5.20 5.40 5.60 5.80 ABR qEHVI-PM-CBD (q=1) qEHVI-PM-CBD (q=8) qNEHVI (q=1) qNEHVI (q=16) qNEHVI (q=32) qNEHVI (q=8) qNEHVI-1 (q=1) qNEHVI-1 (q=16) qNEHVI-1 (q=32) qNEHVI-1 (q=8) (a) 0 50 100 150 200 Batch Iteration -0.20 -0.10 0.00 0.10 0.20 Log Hypervolume Difference AutoML 0 50 100 150 200 Batch Iteration 1.40 1.60 1.80 2.00 2.20 2.40 CarSideImpact 0 50 100 150 200 Batch Iteration 1.00 1.20 1.40 1.60 1.80 2.00 2.20 2.40 ConstrainedBraninCurrin 0 50 100 150 200 Batch Iteration -2.00 -1.50 -1.00 -0.50 0.00 ZDT1 qEHVI-PM-CBD (q=1) qEHVI-PM-CBD (q=16) qEHVI-PM-CBD (q=32) qEHVI-PM-CBD (q=8) qNEHVI (q=1) qNEHVI (q=16) qNEHVI (q=32) qNEHVI (q=8) qNEHVI-1 (q=1) qNEHVI-1 (q=16) qNEHVI-1 (q=32) qNEHVI-1 (q=8) (b) Figure 12: Anytime optimization performance of batch EHVI-based acquisition functions using various qover the number of function evaluations. 1 8 16 32 q -0.20 -0.10 0.00 0.10 Log Hypervolume Difference AutoML 1 8 16 32 q 1.40 1.60 1.80 2.00 2.20 CarSideImpact 1 8 16 32 q 0.90 1.00 1.10 1.20 1.30 1.40 1.50 1.60 ConstrainedBraninCurrin 1 8 16 32 q -2.25 -2.00 -1.75 -1.50 -1.25 -1.00 -0.75 -0.50 ZDT1 DGEMO MOEA/D-EGO TS-TCH TSEMO qEHVI-PM-CBD qNEHVI qNEHVI-1 qNParEGO Figure 13: Final log hypervolume difference with variousqunder a budget of 224 function evaluations. Smaller log hypervolume differences are better. 33H.6 Optimization Performance under Increasing Noise Levels Figure 14 shows the sequential optimization performance of qNEHVI and qNEHVI-1 relative to qEHVI and qNParEGO under increasing noise levels. qNEHVI-1 achieves the best ﬁnal hy- pervolume when the noise standard deviation σ is less than 15% of the range of each objective, but performs worse than qNEHVI earlier in the optimization. qNEHVI is the top performer in high-noise environments. We observe that all methods degrade as the noise level increases, however qNEHVI consistently exhibits excellent performance relative to other methods and only qNEHVI-1 is competitive and only in the low-noise regime. -2.00 -1.75 -1.50 -1.25 -1.00 -0.75 -0.50Log Hypervolume Difference = 1% qNEHVI qEHVI qNEHVI-1 qNParEGO = 2%  = 3%  = 4% 0 100 200 300 400 Function Evaluations -2.00 -1.75 -1.50 -1.25 -1.00 -0.75 -0.50Log Hypervolume Difference = 5% 0 100 200 300 400 Function Evaluations = 10% 0 100 200 300 400 Function Evaluations = 15% 0 100 200 300 400 Function Evaluations = 20% Figure 14: Sequential optimization performance under increasing noise levels on a DTLZ2 problem (d = 6, M = 2). σis the noise standard deviation, which we deﬁne as a percentage of the range of each objective over the entire search space. A noise level of 20% is very high; for comparison, previous work on noisy MOBO has only considered noise levels of 1% [25]. H.7 Optimization Performance on Noiseless Benchmarks We include a comparison of optimization performance onnoiseless benchmarks. Figure 15 shows that qNEHVI performs competitively with qEHVI (-PM-CBD) and outperforms DGEMO, TS-TCH and qNParEGO across all benchmark problems. qNEHVI-1 is also a top performer on noiseless problems and both qNEHVI and qNEHVI-1 show little degradation in performance with increasing levels of parallelism. 340 50 100 150 200 Function Evaluations -0.50 0.00 0.50 1.00 1.50 Log Hypervolume Difference BraninCurrin 0 50 100 150 200 Function Evaluations -2.25 -2.00 -1.75 -1.50 -1.25 -1.00 -0.75 -0.50 DTLZ2 0 50 100 150 200 Function Evaluations -2.50 -2.00 -1.50 -1.00 -0.50 0.00 ZDT1 0 50 100 150 200 Function Evaluations -1.00 -0.50 0.00 0.50 1.00 VehicleSafety DGEMO TS-TCH qEHVI qEHVI-PM-CBD qNEHVI qNEHVI-1 qNParEGO (a) 1 8 16 32 q -0.75 -0.50 -0.25 0.00 0.25 0.50 0.75 1.00 1.25 Log Hypervolume Difference BraninCurrin 1 8 16 32 q -2.40 -2.20 -2.00 -1.80 -1.60 -1.40 -1.20 -1.00 -0.80 DTLZ2 1 8 16 32 q -2.50 -2.25 -2.00 -1.75 -1.50 -1.25 -1.00 -0.75 ZDT1 1 8 16 32 q -1.25 -1.00 -0.75 -0.50 -0.25 0.00 0.25 0.50 0.75 VehicleSafety DGEMO TS-TCH qEHVI-PM-CBD qNEHVI qNEHVI-1 qNParEGO (b) Figure 15: Sequential (a) and parallel (b) optimization Performance on noiseless benchmarks. H.8 Performance of qNEHVI-1 on 5-Objective Optimization We demonstrate that qNEHVI-1 enables scaling to 5-objective problems. To our knowledge, no previous methods leveraging EHVI or HVI (e.g. DGEMO, TSEMO) considers 5-objective problems because of the super-polynomial complexity of the hypervolume indicator. Nevertheless, we show that using CBD and a single sample path approximation,qNEHVI-1 can be used for 5-objective opti- mization. As shown in Figure 16,qNEHVI-1 outperforms qNParEGO and Sobol search. qNEHVI-1 takes on average 73.53 seconds (with an SEM of 1.74 seconds) to generate each candidate, whereas qNParEGO takes 11.37 seconds (with an SEM of 0.97 seconds). 0 100 200 300 400 Function Evaluations -0.60 -0.50 -0.40 -0.30 -0.20 -0.10 0.00 Log Hypervolume Difference DTLZ2-5 Sobol qNEHVI-1 qNParEGO Figure 16: Optimization performance on a 5-objective DTLZ2 problem ( d= 6) with σ= 5%. 35H.9 Performance compared against a Multi-Objective CMA-ES CMA-ES is an evolutionary strategy that is a strong method in single objective optimization, and many works have proposed extensions of CMA-ES to the multi-objective setting [27, 55]. We compare qNEHVI against the COMO-CMA-ES algorithm, which has been shown to outperform MO-CMA- ES on a variety of problems [55].10. We evaluate performance on the SphereEllipsoidal function from Bi-objective Black-Box Optimization Benchmarking Test Suite [6], and we add zero-mean Gaussian noise to each objective with σ= 5% of the range of each objective. We run COMO-CMA-ES with 5 kernels, the same initial quasi-random design as the BO methods, a population size of 10, and an initial step size of 0.2. As shown in Figure 17, the BO methods vastly outperform COMO-CMA-ES. qNEHVI and qNParEGO perform best and are closely followed by qNEHVI-1. 0 50 100 150 200 Function Evaluations 7.20 7.40 7.60 7.80 8.00 8.20 8.40Log Hypervolume Difference SphereEllipsoidal COMO-CMA-ES Sobol TS-TCH qNEHVI qNEHVI-1 qNParEGO Figure 17: Optimization performance on a 2-objective Sphere-Ellipsoidal problem ( d = 5) with σ= 5%. H.10 Importance of Accounting for Noise in DGEMO -15 -10 -5 0 Objective 1 -8 -7 -6 -5 -4 -3 -2 -1 0 1 Objective 2 DGEMO-PM-NEHVI -15 -10 -5 0 Objective 1 DGEMO -15 -10 -5 0 Objective 1 DGEMO-PM Figure 18: An illustration of the effect of noisy observations on the true noiseless Pareto frontiers identiﬁed by DGEMO (right) DGEMO-PM-NEHVI (left, see Appendix H.10). Both algorithms are tested on a BraninCurrin synthetic problem, where observations are corrupted with zero-mean, additive Gaussian noise with a standard deviation of 5% of the range of respective objective. All methods use sequential (q= 1) optimization. 10COMO-CMA-ES is also the only multi-objective CMA-ES that we could ﬁnd with an open-source Python implementation. We use the implementation available at https://github.com/CMA-ES/pycomocma under the BSD 3-clause license. 36Similar to EHVI, DGEMO relies on the observed (noisy) Pareto frontier for batch selection. The right plot in Figure 18 shows that DGEMO exhibits the same clumping behavior in objective space in the noisy setting as EHVI . While DGEMO’s diversity constraints (with respect to the input parameters) make it slightly more robust to noise, the solutions are clustered and the bottom right corner of the Pareto frontier is not identiﬁed. In an attempt to mitigate these issues, we propose an augmented version of DGEMO, which we call DGEMO-PM-NEHVI, as follows: (i) we use the posterior mean at the previously evaluated points to estimate the in-sample Pareto frontier, which we hope will improve robustness to noise when selecting a discrete set of potential candidates using the DGEMO’s ﬁrst-order approximation of the Pareto frontier, and (ii) we use qNEHVI rather than HVI under the posterior mean as the batch selection criterion over the discrete set, subject to DGEMO’s diversity constraints. We ﬁnd that using qNEHVI to integrate over the uncertainty in the Pareto frontier over the previously evaluated points, results in identifying higher quality Pareto frontiers as shown in Figure 18. We also include DGEMO-PM, which uses (i) but not (ii) for completeness. Not only does DGEMO-PM-NEHVI identify much more diverse solutions that provide better coverage across the Pareto frontier, but DGEMO-PM-NEHVI also identiﬁes much better solutions on the lower right portion of the Pareto frontier than DGEMO and DGEMO-PM. DGEMO-PM performs much better than DGEMO and is competitively with DGEMO-PM-NEHVI, which we speculate is because DGEMO uses a ﬁrst-order approximation of the Pareto frontier (using the observed values or using the posterior mean for -PM variants) to generate a discrete set of candidates. Using the posterior mean in this step is important for regularizing against extreme observed values due to noise. qNEHVI is only used as a ﬁltering criterion for batch selection over that discrete set of candidates, subject to DGEMO’s diversity constraints. Hence, qNEHVI has limited control over the batch selection procedure. DGEMO’s ﬁrst-order approximation fundamentally does not account for uncertainty in the Pareto frontier over previously evaluated points. Although one could integrate over the uncertainty in the in-sample Pareto frontier by generating a ﬁrst-order approximation of the Pareto frontier under different sample paths, the graph cut algorithm would yield different families under each sample path. It is unclear how to set the diversity constraints in that setting. We leave this for future work. I Noisy Outcome Constraints While the focus of this work is on developing a scalable parallel hypervolume-based acquisition function for noisy settings, our MC-based approach naturally lends itself to support for constraints. I.1 Derivation of Constrained NEHVI The NEHVI formulation in (2) can be extended to handle noisy observations of outcome constraints. We consider the scenario where we receive noisy observations ofM objectives f(x) ∈RM and V constraints c(v) ∈RV, all of which are assumed to be “black-box”: Dn = {xi,yi,bi}n i=1 where[ yi bi ] ∼N ([ f(xi) c(xi) ] ,Σi ) , Σi ∈R(M+V)×(M+V). We assume, without loss of generality, that c(v) is feasible iff c(v) ≥0. In the constrained optimization setting, we aim to identify the a ﬁnite approximate feasible Pareto set Pfeas = {f(x) |x∈Xn,c(x) ≥0, ∄ x′: c(x′) ≥0 s.t.f(x′) ≻f(x)} of the true feasible Pareto set P∗ feas = {f(x) s.t. c(x) ≥0, ∄ x′: c(x′) ≥0 s.t.f(x′) ≻f(x)}. The natural improvement measure in the constrained setting is feasible HVI, which we deﬁne for a single candidate point xas HVI C(f(x),c(x)|Pfeas) := HVI [f(x)|Pfeas] ·1 [c(x) ≥0]. Taking the expectation over HVIC gives the constrained expected hypervolume improvement: αEHVI C (x) = ∫ HVI C(f(x),c(x)|Pfeas)p(f,c|D)dfdc (19) 37For brevity, we deﬁne Cn = c(Xn),Fn = f(Xn). The noisy expected hypervolume improvement is then deﬁned as: αNEHVI C (x) = ∫ αEHVI C (x|Pfeas)p(Fn,Cn|Dn)dFndCn. (20) Performing feasibility-weighting on the sample-level allows us to include such auxiliary outcome constraints into the full Monte Carlo formulation given in (3) in a straightforward way: ˆαNEHVI c(x) = 1 N N∑ t=1 Kt∑ k=1 [ M∏ m=1 [ z(m) k,t −l(m) k,t ] + V∏ v=1 1 [c(v) t (x) ≥0] ] where z(m) k,t := min [ u(m) k,t , ˜f(m) t (x) ] and l(m) k,t ,u(m) k,t are the mth dimension of the lower and upper vertices of the rectangle Sk,t in the non-dominated partitioning {S1,t,...,S Kt,t}under the feasible sampled Pareto frontier Pfeas,t = Pfeas = {˜ft(x) |x∈Xn,˜ct(x) ≥0, ∄ x′: ˜ct(x′) ≥0 s.t. ˜ft(x′) ≻ ˜ft(x)}. In this formulation, the ∏V v=1 1 [c(v) t (x) ≥0] indicates feasibility of the t-th sample. To permit gradient-based optimization via exact sample-path gradients, we replace the indicator function (which is non-differentiable) with a differentiable sigmoid approximation with a temperature parameter τ, which becomes exact as τ →∞: 1 [c(v)(x) ≥0] ≈s(c(v)(x); τ) := 1 1 + exp(−c(v)(x)/τ) (21) Hence, ˆαNEHVI c(x) ≈ 1 N N∑ t=1 Kt∑ k=1 [ M∏ m=1 [ z(m) k,t −l(m) k,t ] + V∏ v=1 s(c(v) t (x),τ) ] I.2 Derivation of Parallel, Constrained NEHVI The constrained NEHVI can be extended to the parallel setting in a straightforward fashion. The joint constrained hypervolume improvement of a set of points {xi}q i=1 is given by HVI C({f(xi),c(xi)}q i=1) = K∑ k=1 q∑ j=1 ∑ Xj∈Xj (−1)j+1 [( M∏ m=1 [ z(m) k,Xj −l(m) k ] + ) ∏ x′∈Xj V∏ v=1 1 [c(v)(x′) ≥0] ] . and the constrained qEHVI is [11]: αqEHVI C (Xcand|Pfeas) = ∫ HVI C(f(Xcand),c(Xcand)|Pfeas)p(f,c|Dn)dfdc Hence, the constrained qNEHVI is given by: αqNEHVI c(Xcand) = ∫ αqEHVI C (Xcand|Pfeas)p(Fn,Cn|Dn)dFndCn = ∫ HVI C(f(Xcand),c(Xcand)|Pfeas)p(Fn,Cn|Dn)dFndCn (22) Using MC integration for the integral in (22), we have ˆαqNEHVI c(Xcand) = 1 N N∑ t=1 HVI c( ˜ft(Xcand),˜ct(Xcand)|Pfeas,t). (23) Under the CBD formulation, the constrained qNEHVI is given by ˆαqNEHVI ({x1,..., xi}) = 1 N N∑ t=1 HVI C ( {˜ft(xj),˜ct(xj)}i−1 j=1}|P feas,t ) + 1 N N∑ t=1 HVI C (˜ft(xi),˜ct(xi) |Pfeas,t ∪{ ˜ft(xj),˜ct(xj)}i−1 j=1} ) . (24) 38As in (6), the ﬁrst term is a constant when generating candidate iand the second term is the NEHVI of xi. J Evaluating Methods on Noisy Benchmarks Given noisy observations, we can no longer compute the true Pareto frontier over the in-sample points Xn. Moreover, the subset of Pareto optimal designsX∗ n = {x∈Xn, ∄ x′∈Xns.t.f(x′) ≻f(x)} from the previously evaluated points may not be identiﬁed due to noise. For the previous results reported in this paper, we evaluate each method according to hypervolume dominated by the true unknown Pareto frontier of the noiseless objectives over thein-sample points. In practice, decision- makers would often select one of the in-sample points according to their preferences. If the decision maker only has noisy observations, selecting an in-sample point may be preferable to evaluating a new out-of-sample point according to the model’s beliefs. An alternative evaluation method would be use the model’s posterior mean to identify what it believes is the Pareto optimal set of in-sample designs. The hypervolume dominated by the true Pareto frontier of noiseless objectives over that set of selected designs could be computed and used for comparing the performance of different methods. Results using this procedure are shown in Figure 19. The quality of the Pareto set depends on the model ﬁt. Several methods have worse performance over time (e.g. qEHVI and qPAREGO on the ZDT1 problem), likely due to the collection of outlier observations that degrade the model ﬁt. Nevertheless, qNEHVI consistently has the strongest performance. An alternative to the in-sample evaluation techniques described above would be to use the model to identify the Pareto frontier across the entire search space (in-sample or out-of-sample). For example, Hernández-Lobato et al. [25] used NSGA-II to optimize the model’s posterior mean and identify the model estimated Pareto frontier. For benchmarking purposes on expensive-to-evaluate functions (e.g. in AutoML or ABR), this is prohibitively expensive. Moreover, such a method is less appealing in practice because a decision-maker would have to select out-of-sample points according to the posterior mean and then evaluate a set of preferred designs on the noisy objective to verify that the model predictions are fairly accurate at those out-of-sample designs. Therefore, in this work we evaluate methods based on the in-sample designs. 390 50 100 150 200 Function Evaluations 0.60 0.80 1.00 1.20 1.40 1.60 1.80Log Hypervolume Diﬀerence BraninCurrin 0 50 100 150 200 Function Evaluations -1.60 -1.40 -1.20 -1.00 -0.80 -0.60 -0.40 -0.20 0.00 ZDT1 0 50 100 150 200 Function Evaluations 5.50 5.60 5.70 5.80 5.90 6.00 6.10 Adaptive Bitrate 0 50 100 150 200 Function Evaluations -0.50 -0.25 0.00 0.25 0.50 0.75 1.00 1.25 1.50 VehicleSafety MESMO PFES Sobol TS-TCH qEHVI qEHVI-PM qNEHVI qNParEGO qParEGO (a) 0 50 100 150 200 Function Evaluations -0.05 0.00 0.05 0.10 0.15 0.20 0.25 Log Hypervolume Diﬀerence AutoML 0 50 100 150 200 Function Evaluations 1.40 1.60 1.80 2.00 2.20 2.40 CarSideImpact 0 50 100 150 200 Function Evaluations 1.40 1.60 1.80 2.00 2.20 2.40 2.60 ConstrainedBraninCurrin qNEHVI qParEGO qNParEGO TS-TCH qEHVI qEHVI-PM MESMO PFES (b) Figure 19: Sequential optimization performance using based on the model-identiﬁed Pareto set across in-sample points. 40
```

## **Instructions:**
1. Analyze the paper based on the categories listed below.
2. Your response **must be a valid JSON object** that can be directly parsed using `json.loads()`.
3. Do not include any extra text, explanations, or formatting outside of the JSON object.
4. **If a field has no available information, set its value to `"Not mentioned"` instead of leaving it empty.**
5. Ensure that the JSON format is correct, including the use of **double quotes (`"`) for all keys and values.**
## **Output Format (JSON)**:
```json
{
    "main_contributions": "<Concise description of the main research problem and contributions>",
    "methodology": "<Brief explanation of the key techniques, models, or algorithms>",
    "experimental_setup": "<Description of datasets, benchmarks, and validation methods>",
    "limitations": "<Summary of weaknesses, constraints, or assumptions>",
    "future_research_directions": "<Potential areas for extending this research>"
}
```
Output:
{
    "main_contributions": "The research addresses the challenging problem of optimizing multiple competing black-box objectives, particularly when observations are corrupted by noise and when large batches of candidates need to be evaluated in parallel. It proposes NEHVI (noisy expected hypervolume improvement), a novel acquisition function that applies a Bayesian treatment to the popular expected hypervolume improvement (EHVI) criterion by integrating over the uncertainty in the Pareto frontier, making it robust to observation noise. The paper also introduces qNEHVI, a parallel variant that reduces the computational complexity of parallel EHVI from exponential to polynomial with respect to batch size, and is one-step Bayes-optimal for hypervolume maximization in both noisy and noiseless environments. A key enabler is the general-purpose, differentiable, cached box decomposition (CBD) implementation, which dramatically speeds up critical computations. Empirically, qNEHVI is shown to be substantially more robust to noise than existing MOBO approaches, achieve state-of-the-art optimization performance, and maintain competitive wall-times in large-batch environments.",
    "methodology": "The core methodology extends Expected Hypervolume Improvement (EHVI) to noisy, parallel settings. NEHVI is derived by iterating the expectation over the posterior distribution of function values at previously evaluated points, thereby integrating over the uncertainty in the Pareto frontier. Its parallel variant, qNEHVI, uses a sequential greedy approximation for batch selection. To address computational complexity, a Cached Box Decomposition (CBD) technique is introduced where Pareto frontiers and box decompositions are computed once for fixed posterior samples and cached for the duration of acquisition function optimization. This allows efficient conditional posterior sampling for new candidates using low-rank updates and the reparameterization trick. The acquisition function (ˆαNEHVI) is differentiable, enabling efficient gradient-based optimization with methods like L-BFGS-B, and theoretical convergence guarantees are provided under Sample Average Approximation (SAA). A cheaper approximation, qNEHVI-1, utilizes a single approximate Gaussian Process sample path via Random Fourier Features (RFFs) for faster optimization.",
    "experimental_setup": "The methods were empirically evaluated on a variety of synthetic and real-world benchmark problems. Synthetic problems included noisy variants of BraninCurrin (M=2, d=2) and DTLZ2 (M=2, d=6), with observations corrupted by zero-mean additive Gaussian noise (5% or 10% of objective range). Real-world applications comprised Adaptive Bitrate (ABR) Control Policy Optimization (M=2, d=4), Vehicle Design Optimization (M=3, d=5), AutoML (M=2, d=8), CarSideImpact (M=4, d=7), Constrained BraninCurrin (M=2, V=2, d=2), and SphereEllipsoidal (M=2, d=5). Comparison was made against several baselines: PESMO, MESMO (extended for noise), PFES, DGEMO, MOEA/D-EGO, TSEMO, TS-TCH, qEHVI (and qEHVI-PM-CBD), qNParEGO, qParEGO, and COMO-CMA-ES. All methods were initialized with 2(d+1) points from a scrambled Sobol sequence. Multi-start L-BFGS-B with exact gradients (or finite differences for PFES) was used for optimization. Performance was measured by the logarithm of the difference in hypervolume between the true Pareto frontier and the approximate Pareto frontier recovered, computing hypervolume dominated by the noiseless Pareto frontier over observed points.",
    "limitations": "The study acknowledges limitations, including the poor performance of information-theoretic acquisition functions on the benchmarks, though these could potentially offer decoupled objective evaluations for resource-intensive scenarios with improved optimization. The exact hypervolume computation still exhibits super-polynomial complexity with respect to the number of objectives, which could pose a challenge for problems with a very high number of objectives, despite the CBD approach improving complexity for batch size. The performance of the qNEHVI-1 approximation, which relies on Random Fourier Features, was observed to degrade in higher dimensional search spaces, suggesting a need for further investigation into the impact of the number of Fourier basis functions.",
    "future_research_directions": "Future research directions include investigating improved optimization procedures for information-theoretic acquisition functions to enhance their performance and provide principled approaches for selecting evaluation sources on a budget. Combining qNEHVI with differentiable approximate methods for computing hypervolume, such as those proposed by Couckuyt et al. [9] or Golovin & Zhang [23], could lead to further speed-ups. Additionally, further study is needed on how the number of Fourier basis functions affects the performance of qNEHVI-1 in high-dimensional search spaces. The authors also suggest exploring the extension of DGEMO's graph cut algorithm to account for uncertainty in the in-sample Pareto frontier by generating first-order approximations under different sample paths, while addressing the setting of diversity constraints. More broadly, the core ideas and the CBD approach are hoped to provide a framework for developing new computationally efficient MOBO methods."
}
