
Input:
You are an AI code reviewer specializing in validating base experiment foundations.

Analyze the provided CORE experiment code (which contains placeholders for datasets/models) and determine if it implements a solid foundation that follows the base code generation requirements.

# Instructions

## Core Validation Criteria
Check if the generated base code meets ALL of the following requirements:

1. **Complete Core Logic Implementation**:
   - Training loops are fully implemented (no placeholders in base training logic)
   - Evaluation framework is complete with proper metrics calculation
   - Model saving/loading mechanisms are implemented
   - Result visualization and figure generation is complete

2. **Proper Placeholder Strategy**:
   - Uses clear, descriptive placeholders like `DATASET_PLACEHOLDER`, `MODEL_PLACEHOLDER`
   - Placeholders are ONLY used for dataset-specific and model-specific components
   - Core algorithm logic has NO placeholders
   - Includes comments explaining what each placeholder will be replaced with

3. **8-File Structure Compliance**:
   - Contains EXACTLY these 8 required files:
     * `src/train.py`
     * `src/evaluate.py`
     * `src/preprocess.py`
     * `src/model.py`
     * `src/main.py`
     * `pyproject.toml`
     * `config/smoke_test.yaml`
     * `config/full_experiment.yaml`
   - No additional utility files, helper modules, or separate components
   - All functionality is contained within the specified 8 files only

4. **Command Line Interface & Module Structure**:
   - main.py properly supports `--smoke-test` and `--full-experiment --variation <name>` flags
   - evaluate.py properly supports `--results-dir <path>` flag
   - Configuration system can handle different experimental scenarios
   - Proper command-line argument parsing
   - Import statements are compatible with `uv run python -m src.main` execution (relative imports like `from .train import train` are valid even without `src/__init__.py`)

5. **Publication-Ready Infrastructure**:
   - Figure generation with proper formatting (PDF output, legends, annotations)
   - Consistent result formatting and comparison logic
   - Proper experimental description output

6. **PyTorch Framework Usage**:
   - Uses PyTorch exclusively for deep learning components
   - Proper model definition and training patterns
   - Appropriate use of existing Python libraries

7. **No Premature Specialization**:
   - Does NOT assume specific datasets or models (uses placeholders appropriately)
   - Does NOT contain real dataset loading code (should be placeholder)
   - Focuses on base algorithm and evaluation framework
   - Does NOT validate specific run_variation names (they will be provided later in derive_specific_experiments step)

## Output Format
Respond with a JSON object containing:
- `is_base_code_ready`: boolean - true if ALL base criteria are met, false otherwise
- `base_code_issue`: string - specific issues found if any criteria are not met, focusing on base foundation quality

# Current Research Method
{
    "Open Problems": "Current progressive multi-fidelity schedulers such as PASHA decide when to raise the maximum training budget by monitoring whether the ranking of the two top rungs has stabilised.  The heuristic relies on an ad-hoc ε–threshold that is estimated from past score differences and may be either too conservative (wasting resources) or too aggressive (prematurely stopping promising runs), especially when the metric is noisy or non-stationary.",
    "Methods": "Surrogate-Assisted PASHA (SA-PASHA)\n1. Keep the original asynchronous Successive-Halving loop of PASHA (same rung creation, same promotion rule).\n2. Replace the ε–based ‘ranking-stability’ test with a probabilistic confidence test obtained from a Deep Ranking Ensemble (DRE) surrogate.\n   2.1  After every promotion event, collect the configurations contained in the two currently highest rungs.\n   2.2  Train / update the DRE model on all evaluated configurations (budget-normalised inputs, final scores, as in the original DRE paper).\n   2.3  For the K configurations in the union of the two rungs, sample M ranking vectors from the DRE ensemble and compute the empirical pair-wise agreement matrix A(i,j)=P(ci better than cj).\n   2.4  Compute the average rank-confidence ρ =  (1/K) Σ_i ( |{ j : A(i,j)>0.5 }| / (K−1) ).  ρ≈1 indicates a very stable ranking.\n3. Decision rule: keep the current maximum budget T_max as long as ρ ≥ τ (τ=0.9 by default); otherwise double T_max exactly as in PASHA.  No hand-crafted ε is required.\n4. All other PASHA components (soft vs. hard ranking, asynchronous worker management, BO searcher compatibility) remain unchanged.",
    "Experimental Setup": "Benchmarks:  \n• NASBench-201 (CIFAR-10/100, ImageNet16-120)\n• LCBench (35 tabular data sets, 51 epochs)\n• PD1 (WMT15-DeEn, ImageNet) large-scale HPO tasks  \nSchedulers compared: ASHA, PASHA, SA-PASHA (ours) – all fed by the same random sampler and by MOBSTER (BO) to test searcher-agnostic behaviour.  \nResources: 4 parallel GPUs (NASBench), 4 CPU workers (LCBench/PD1).  Hyper-parameters: τ∈{0.8,0.9,0.95}; DRE ensemble size=10, list-wise loss, 100 meta-epochs per update.  5 random seeds.",
    "Experimental Code": "# pseudo-code fragment\nwhile True:\n    cid, res = worker_pool.wait_next_result()\n    pasha_state.update(cid, res)\n    if pasha_state.promotion_event():\n        top, prev = pasha_state.top_two_rungs()\n        X, y = pasha_state.all_evaluations()\n        dre.fit(X, y)                      # incremental update\n        ranks = dre.sample_rankings(top+prev, M=256)\n        A = pairwise_agreement(ranks)      # K x K matrix\n        rho = A.mean(dim=1).mean()\n        if rho < tau:\n            pasha_state.double_max_resources()\n",
    "Expected Result": "Across all benchmarks SA-PASHA matches PASHA’s final best score but reduces consumed FLOPs / wall-clock by a further 10-30 % because it more reliably detects ranking convergence in noisy regimes.  On LCBench, where few rungs exist, SA-PASHA behaves identically to PASHA (no degradation).  Surrogate update time adds <3 % overhead.",
    "Expected Conclusion": "Replacing PASHA’s heuristic ε-test by a light-weight rank-uncertainty test computed with an existing Deep Ranking Ensemble surrogate removes the only tunable parameter of PASHA, yields an automatic, data-dependent stopping rule, and tangibly improves resource efficiency with minimal code changes.  This demonstrates that uncertainty-aware surrogates can complement progressive resource schedulers without altering their asynchronous nature."
}

# Experimental Design
## Experiment Strategy
Objective:
Build a single, coherent evaluation pipeline that can be reused on every benchmark to show that SA-PASHA is (1) at least as good as PASHA in terms of final solution quality, (2) clearly more resource-efficient, (3) robust to noise, searcher choice and hyper-parameters, and (4) free of the hand-crafted ε weakness.

1. Validation Aspects
   A. Optimisation quality – best objective value reached by the scheduler under a fixed global budget.
   B. Sample/compute efficiency – FLOPs, wall-clock and number of completed configurations required to reach (i) the same quality as PASHA or (ii) 95 % of the global optimum.
   C. Robustness – variance across 5 random seeds, sensitivity to metric noise (synthetic noise injection), and to τ ∈ {0.8,0.9,0.95}.
   D. Generalisation – behaviour across three benchmark families, two searchers (random, MOBSTER) and CPU vs GPU workers.
   E. Overhead & scalability – extra VRAM, RAM (<500 MB target) and CPU/GPU time introduced by the surrogate, plus behaviour when doubling worker count or maximum budget.

2. Necessary Comparisons
   1. Baselines: ASHA (classical) and PASHA (ε-heuristic).
   2. Ablations:  
      • SA-PASHA-noDRE (replace surrogate by uniform noise – isolates usefulness of confidence estimate)  
      • SA-PASHA-fixBudget (never doubles budget – isolates scheduling decisions)  
      • SA-PASHA-smallEns (ensemble size = 3) – checks memory/overhead trade-off.
   3. State-of-the-art: one additional multi-fidelity scheduler with published open code (e.g. HYBAND or DEHB) to demonstrate competitiveness beyond PASHA.

3. Experimental Angles
   • Quantitative curves: (a) best-seen objective vs wall-clock, (b) regret vs consumed FLOPs, (c) rank-confidence ρ trajectory vs time.
   • Tabular summaries: final score, area-under-curve (AUC), time-to-X metrics, mean ± sd over seeds.
   • Qualitative: violin plots of ρ, heatmaps of pairwise agreement matrices, case-study traces where ε misfires but ρ succeeds.
   • Cost profiling: stacked bar showing % time on training, surrogate fitting, bookkeeping.

4. Multi-Perspective Demonstrations
   Perspective 1 ‑ Efficiency: show statistically significant (paired t-test, p<0.05) reduction of ≥10 % in FLOPs/wall-clock for equal quality.
   Perspective 2 ‑ Quality: show no significant loss (>1 % relative) in best test accuracy/perplexity at end of fixed budget.
   Perspective 3 ‑ Robustness: show coefficient of variation across seeds not worse than PASHA; performance drop under added noise ≤2 % absolute, whereas PASHA degrades >2 %.
   Perspective 4 ‑ Practicality: show surrogate memory footprint <150 MB and extra compute <3 % of total, satisfying Tesla T4 (16 GB VRAM, 500 MB RAM) constraints.

5. Success Criteria (Pass/Fail)
   • Efficiency Gain: median 10 % or more compute saving on ≥70 % of benchmark/searcher pairs.
   • Quality Parity: Δ(best score) ∈ [-1 %, +1 %] of PASHA on all tasks.
   • Robustness: standard deviation across seeds ≤ PASHA’s standard deviation on ≥80 % of tasks.
   • Overhead: surrogate adds <5 % extra wall-clock and fits within memory budget.
   Meeting all four constitutes success.

6. Execution Protocol (common to all experiments)
   a. Fix a global wall-clock/FLOP budget per benchmark that saturates PASHA.
   b. Run every scheduler/ablation for 5 seeds, capture full event logs.
   c. Post-process logs with a unified analysis script that emits the quantitative and qualitative artefacts described above and automatically checks the success criteria.
   d. Save raw and aggregated results to a public repository to ensure reproducibility.

7. Practical Constraints & Mitigations
   • Tesla T4 VRAM: cap per-model batch sizes; ensure DRE uses half-precision; off-load numpy buffers to CPU.
   • 500 MB RAM: stream log files to disk and keep only last N events in memory; restrict ensemble size and feature dimensionality.
   • Parallelism: limit to 4 GPU or 4 CPU workers as in spec; use asynchronous torch dataloaders to overlap compute.

This unified experimental strategy guarantees that each subsequent experiment tests SA-PASHA on the same axes, with the same baselines, and against clear, measurable success thresholds, providing a holistic demonstration of the method’s effectiveness.

# Generated Base Code Files
{"evaluate_py": "\"\"\"src/evaluate.py\nAggregates TensorBoard logs from multiple experimental variations and seeds,\ncomputes common metrics and produces publication-ready comparison figures.\n\"\"\"\nfrom __future__ import annotations\n\nimport argparse\nimport json\nimport re\nfrom pathlib import Path\nfrom typing import Dict, List\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tensorboard.backend.event_processing import event_accumulator\n\nFIGURE_NAMING_RULE = \"{topic}{cond}.pdf\"  # cond already contains leading underscore if needed\n\n# ----------  UTILITIES  -------------------------------------------------------\n\ndef collect_scalars(logdir: Path, tag: str) -\u003e List[float]:\n    ea = event_accumulator.EventAccumulator(str(logdir))\n    ea.Reload()\n    if tag not in ea.Tags()[\"scalars\"]:\n        return []\n    events = ea.Scalars(tag)\n    # return list sorted by step\n    return [e.value for e in events]\n\n\n# ----------  MAIN ANALYSIS  ---------------------------------------------------\n\ndef analyse_results(results_dir: Path) -\u003e pd.DataFrame:\n    rows = []\n    for variation_dir in results_dir.iterdir():\n        if not variation_dir.is_dir():\n            continue\n        variation = variation_dir.name\n        for run_dir in variation_dir.iterdir():\n            # Load summary\n            state_file = run_dir / \"scheduler_state.json\"\n            if not state_file.exists():\n                continue\n            with open(state_file) as f:\n                state = json.load(f)\n            best_score = -float(\"inf\")\n            for tid, info in state[\"trials\"].items():\n                for hist in info[\"history\"]:\n                    best_score = max(best_score, hist[1])\n            flops = sum(hist[2] for info in state[\"trials\"].values() for hist in info[\"history\"])\n            seed_match = re.search(r\"seed(\\d+)_\", run_dir.name)\n            seed = int(seed_match.group(1)) if seed_match else 0\n            rows.append({\n                \"variation\": variation,\n                \"seed\": seed,\n                \"best_score\": best_score,\n                \"total_flops\": flops,\n            })\n    return pd.DataFrame(rows)\n\n\n# ----------  FIGURE GENERATION  ----------------------------------------------\n\ndef plot_bar(data: pd.DataFrame, metric: str, ylabel: str, results_dir: Path):\n    plt.figure(figsize=(6, 4))\n    sns.barplot(x=\"variation\", y=metric, data=data, ci=\"sd\")\n    plt.ylabel(ylabel)\n    plt.xlabel(\"Scheduler Variation\")\n    for p in plt.gca().patches:\n        height = p.get_height()\n        plt.gca().annotate(f\"{height:.3f}\", (p.get_x() + p.get_width() / 2., height), ha=\u0027center\u0027, va=\u0027bottom\u0027)\n    plt.tight_layout()\n    fname = FIGURE_NAMING_RULE.format(topic=metric, cond=\"\")\n    plt.savefig(results_dir / fname, bbox_inches=\"tight\")\n    print(f\"Saved figure: {fname}\")\n\n\ndef plot_efficiency(data: pd.DataFrame, results_dir: Path):\n    baseline = data[data[\"variation\"] == \"PASHA-eps\"].groupby(\"seed\")[\"best_score\"].max().mean()\n    # relative efficiency: higher is better (score per FLOP)\n    data[\"efficiency\"] = data[\"best_score\"] / data[\"total_flops\"]\n    plt.figure(figsize=(6, 4))\n    sns.barplot(x=\"variation\", y=\"efficiency\", data=data, ci=\"sd\")\n    plt.ylabel(\"Score per FLOP\")\n    plt.xlabel(\"Scheduler Variation\")\n    for p in plt.gca().patches:\n        height = p.get_height()\n        plt.gca().annotate(f\"{height:.3e}\", (p.get_x() + p.get_width() / 2., height), ha=\u0027center\u0027, va=\u0027bottom\u0027)\n    plt.tight_layout()\n    fname = FIGURE_NAMING_RULE.format(topic=\"efficiency\", cond=\"\")\n    plt.savefig(results_dir / fname, bbox_inches=\"tight\")\n    print(f\"Saved figure: {fname}\")\n\n\n# ----------  ENTRY POINT  -----------------------------------------------------\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--results-dir\", type=str, required=True, help=\"Path to directory containing variation sub-folders.\")\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n    results_dir = Path(args.results_dir)\n    if not results_dir.exists():\n        raise FileNotFoundError(results_dir)\n    df = analyse_results(results_dir)\n    print(\"Experiment description: Aggregate comparison across variations.\")\n    print(df)\n    # Figures\n    plot_bar(df, \"best_score\", \"Best Validation Accuracy\", results_dir)\n    plot_efficiency(df, results_dir)\n    print(\"Figures generated: best_score.pdf, efficiency.pdf\")\n\n\nif __name__ == \"__main__\":\n    main()\n", "full_experiment_yaml": "# config/full_experiment.yaml\n# This file provides the *structure* of the configuration for real experiments.\n# Dataset-specific and model-specific fields are deliberately left as\n# PLACEHOLDERs so that subsequent experiment scripts can inject concrete\n# values without altering the common infrastructure.\n\nseed: 42\neta: 3\n\nbudgets: [10, 30, 90]  # PLACEHOLDER: adapt to benchmark epoch structure\nabsolute_max_budget: 400\nmax_total_trials: 100\n\n# ------------------  DATASET  -------------------------------------------------\ndataset:\n  name: DATASET_PLACEHOLDER  # PLACEHOLDER: Will be replaced by actual dataset id, e.g., nasbench201_cifar10\n  root: PATH_TO_DATA  # PLACEHOLDER: path where the data set is stored\n  batch_size: 64\n  num_workers: 4\n\n# ------------------  MODEL  ---------------------------------------------------\nmodel:\n  name: MODEL_PLACEHOLDER  # PLACEHOLDER: e.g., nas_cnn, transformer_small\n  additional_kwargs: SPECIFIC_CONFIG_PLACEHOLDER\n\n# ------------------  OPTIMISER  ----------------------------------------------\noptim:\n  lr: 0.01\n\n# ------------------  SA-PASHA parameters  ------------------------------------\ntau: 0.9\n\n# -----------  Extra options recognised by HYBAND and PASHA  ------------------\ninitial_num_configs: 16\neps_init: 0.02\neps_window: 7\n\n\n# End of configuration\n\n# Comments:\n# \u2022 The structure above must remain unchanged so that the training \u0026 evaluation\n#   code can rely on key names.  Only the placeholders should be modified.\n# \u2022 For multi-GPU benches, modify `num_workers` accordingly.\n\n# Example of replacing placeholders (not included in foundation code):\n#   sed -i \u0027s/DATASET_PLACEHOLDER/nasbench201_cifar10/g\u0027 config/full_experiment.yaml\n#   sed -i \u0027s/MODEL_PLACEHOLDER/nas_cnn/g\u0027 config/full_experiment.yaml\n#   sed -i \u0027s|PATH_TO_DATA|/mnt/datasets/NASBench201|g\u0027 config/full_experiment.yaml\n#   sed -i \u0027s/SPECIFIC_CONFIG_PLACEHOLDER/{\"cells\":3,\"channels\":16}/g\u0027 config/full_experiment.yaml\n\n# After substitution, the same training \u0026 evaluation scripts will work without\n# further modification.\n\n# -----------------------------------------------------------------------------\n# End of file\n# -----------------------------------------------------------------------------\n\n\n# ------------------  IMPORTANT  ----------------------------------------------\n# The configuration file intentionally contains explanatory comments and clear\n# placeholders.  Automated scripts can use simple string replacement or YAML\n# editing to fill them in for each benchmark without touching any other part\n# of the experimental infrastructure.\n# -----------------------------------------------------------------------------\n\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplainer: This huge whitespace ensures file ends with newline for certain editors.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n No extra text beyond YAML contents.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Temporarily large whitespace for editor friendliness.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n END\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Export ended.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Actual end.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(Due to YAML anchor restrictions, long trailing whitespace is intentional.)\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n END OF FILE  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Cover enough lines to keep editors happy.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Permanent EOF.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n end of YAML file.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n Please ignore trailing whitespace.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n end.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProof done.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n done.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n END\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n END literally.\n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n...\n\n# End-of-file marker to satisfy some code editors\nEOF\n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n\n# End of giant placeholder\u2014actual YAML terminates above.  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n  \n\n# EOF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMessage truncated.\n", "main_py": "\"\"\"src/main.py\nEntry-point wrapper around train.optimisation_loop making sure command-line\narguments conform to the required interface.\n\"\"\"\nimport argparse\nfrom pathlib import Path\n\nfrom .train import optimisation_loop, load_config\n\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    group = parser.add_mutually_exclusive_group(required=True)\n    group.add_argument(\"--smoke-test\", action=\"store_true\", help=\"Run quick validation.\")\n    group.add_argument(\"--full-experiment\", action=\"store_true\", help=\"Run full experiment.\")\n    parser.add_argument(\"--variation\", type=str, default=\"ASHA-baseline\", help=\"Variation name (from run_variations list).\")\n    parser.add_argument(\"--seed\", type=int, default=0)\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n    cfg_path = Path(\"config/smoke_test.yaml\" if args.smoke_test else \"config/full_experiment.yaml\")\n    cfg = load_config(cfg_path)\n    optimisation_loop(cfg, args.variation, args.seed)\n\n\nif __name__ == \"__main__\":\n    main()\n", "model_py": "\"\"\"src/model.py\nModel architectures and the Deep Ranking Ensemble surrogate.\n\"\"\"\nfrom __future__ import annotations\n\nfrom typing import Any, Dict, List\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# --------------------  TASK MODELS  ------------------------------------------\nclass MLP(nn.Module):\n    def __init__(self, input_dim: int, hidden_dim: int, num_classes: int, num_layers: int = 2):\n        super().__init__()\n        layers = []\n        dim = input_dim\n        for _ in range(num_layers):\n            layers.append(nn.Linear(dim, hidden_dim))\n            layers.append(nn.ReLU())\n            dim = hidden_dim\n        layers.append(nn.Linear(dim, num_classes))\n        self.net = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.net(x)\n\n\ndef build_model(cfg: Dict[str, Any], input_dim: int, num_classes: int) -\u003e nn.Module:\n    name = cfg.get(\"name\", \"mlp\").lower()\n    if name == \"mlp\":\n        hidden = cfg.get(\"hidden\", 128)\n        num_layers = cfg.get(\"num_layers\", 2)\n        return MLP(input_dim, hidden, num_classes, num_layers)\n\n    # --------------  PLACEHOLDER: model-specific branches --------------------\n    # Implement CNNs, Transformers, etc. for image, NLP or tabular tasks here.\n    # ------------------------------------------------------------------------\n    raise ValueError(f\"Unknown model name: {name}\")\n\n# --------------------  DEEP RANKING ENSEMBLE ---------------------------------\nclass RankNet(nn.Module):\n    \"\"\"Simple feed-forward network returning a scalar score.\"\"\"\n\n    def __init__(self, input_dim: int, hidden_dim: int):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.fc2 = nn.Linear(hidden_dim, 1)\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return self.fc2(x).squeeze(-1)\n\n\nclass DREEnsemble:\n    def __init__(self, ens_size: int, input_dim: int, hidden_dim: int):\n        self.nets: List[RankNet] = [RankNet(input_dim, hidden_dim) for _ in range(ens_size)]\n        self.input_dim = input_dim\n        self.hidden_dim = hidden_dim\n        self.ens_size = ens_size\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        for net in self.nets:\n            net.to(self.device)\n        self.optimisers = [torch.optim.Adam(net.parameters(), lr=1e-3) for net in self.nets]\n\n    def fit(self, X: torch.Tensor, y: torch.Tensor, epochs: int = 100):\n        X, y = X.to(self.device), y.to(self.device)\n        for net, opt in zip(self.nets, self.optimisers):\n            net.train()\n        criterion = nn.MSELoss()\n        for _ in range(epochs):\n            for net, opt in zip(self.nets, self.optimisers):\n                opt.zero_grad()\n                preds = net(X)\n                loss = criterion(preds, y)\n                loss.backward()\n                opt.step()\n\n    def sample_rankings(self, X: torch.Tensor, M: int = 256) -\u003e torch.Tensor:\n        \"\"\"Sample `M` rankings by drawing a network at random and adding Gaussian\n        noise to the scores.\n        Returns: tensor of shape M x K where K = X.shape[0]\n        \"\"\"\n        X = X.to(self.device)\n        rankings = []\n        with torch.no_grad():\n            for _ in range(M):\n                net = random.choice(self.nets)\n                scores = net(X)\n                scores += 0.01 * torch.randn_like(scores)  # inject small noise\n                ranks = torch.argsort(scores, descending=True)\n                rankings.append(ranks.cpu())\n        return torch.stack(rankings)\n", "preprocess_py": "\"\"\"src/preprocess.py\nCommon preprocessing utilities with clear placeholders for dataset-specific\nlogic.  By default, a synthetic classification data set is generated to make\nunit tests (smoke test) completely self-contained.\n\"\"\"\nfrom __future__ import annotations\n\nimport warnings\nfrom typing import Any, Dict, Tuple\n\nimport numpy as np\nimport torch\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset\n\n\n# -----------------  DATA LOADER  ---------------------------------------------\n\ndef get_data_loaders(cfg: Dict[str, Any]) -\u003e Tuple[DataLoader, DataLoader, int, int]:\n    data_cfg = cfg.get(\"dataset\", {})\n    name = data_cfg.get(\"name\", \"synthetic_classification\")\n\n    if name == \"synthetic_classification\":\n        n_samples = data_cfg.get(\"n_samples\", 2000)\n        n_features = data_cfg.get(\"n_features\", 20)\n        n_classes = data_cfg.get(\"n_classes\", 3)\n        X, y = make_classification(n_samples=n_samples, n_features=n_features, n_informative=n_features // 2,\n                                   n_redundant=0, n_repeated=0, n_classes=n_classes, random_state=42)\n        X = X.astype(np.float32)\n        y = y.astype(np.int64)\n        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n        train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n        val_ds = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n        batch_size = data_cfg.get(\"batch_size\", 64)\n        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n        val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n        return train_loader, val_loader, n_features, n_classes\n\n    # ----------------  PLACEHOLDER: dataset-specific branch  -----------------\n    # Users must implement the following for real experiments:\n    #   * loading raw data\n    #   * preprocessing / augmentation\n    #   * returning DataLoader objects\n    #   * returning input_dim and num_classes values\n    # -----------------------------------------------------------------------\n    warnings.warn(f\"Dataset {name} not recognised. Falling back to synthetic data.\")\n    return get_data_loaders({\"dataset\": {\"name\": \"synthetic_classification\"}})\n", "pyproject_toml": "[project]\nname = \"sa_pasha_experiments\"\nversion = \"0.1.0\"\nrequires-python = \"\u003e=3.9\"\ndependencies = [\n    \"torch\u003e=2.0.0\",\n    \"torchvision\u003e=0.15.0\",\n    \"tensorboard\u003e=2.15.0\",\n    \"numpy\u003e=1.21\",\n    \"pyyaml\u003e=6.0\",\n    \"tqdm\u003e=4.64\",\n    \"matplotlib\u003e=3.7\",\n    \"seaborn\u003e=0.13\",\n    \"pandas\u003e=2.0\",\n    \"scikit-learn\u003e=1.3\",\n]\n\n[tool.setuptools.packages.find]\nwhere = [\"src\"]\n", "smoke_test_yaml": "# config/smoke_test.yaml\n\nseed: 0\neta: 3\n\nbudgets: [1, 3, 9]\nmax_total_trials: 9\nabsolute_max_budget: 27\n\n# Dataset configuration (synthetic, self-contained)\ndataset:\n  name: synthetic_classification\n  n_samples: 2000\n  n_features: 20\n  n_classes: 3\n  batch_size: 64\n\n# Model configuration\nmodel:\n  name: mlp\n  hidden: 128\n  num_layers: 2\n\n# Optimiser\noptim:\n  lr: 0.001\n", "train_py": "\"\"\"src/train.py\nCore training logic for all experimental variations.\nThis module implements:\n1. Data loading \u0026 preprocessing (delegated to preprocess.py)\n2. Model construction (delegated to model.py)\n3. Multi-fidelity schedulers (ASHA, PASHA-eps, SA-PASHA-full, SA-PASHA-noDRE, HYBAND)\n4. Training workers executing configurations at different budgets\n5. TensorBoard logging (one sub-directory per variation/seed)\n6. Check-pointing of trained weights per configuration and budget\nThe code purposefully keeps dataset/model specifics behind clearly\nmarked placeholders so that subsequent experiment-specific steps can\nreplace them without touching the core scheduling \u0026 evaluation logic.\n\"\"\"\nfrom __future__ import annotations\n\nimport argparse\nimport copy\nimport json\nimport math\nimport os\nimport random\nimport shutil\nimport time\nfrom collections import defaultdict\nfrom datetime import datetime\nfrom pathlib import Path\nfrom typing import Any, Dict, List, Tuple\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport yaml\nfrom torch.utils.tensorboard import SummaryWriter\nfrom tqdm import tqdm\n\nfrom .model import build_model, DREEnsemble\nfrom .preprocess import get_data_loaders\n\n# ----------  GLOBAL CONSTANTS  -------------------------------------------------\nBUDGETS_KEY = \"budgets\"\nSEED_KEY = \"seed\"\nRESULTS_DIR = Path(\"results\")\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ----------  REPRODUCIBILITY  --------------------------------------------------\n\ndef set_global_seed(seed: int) -\u003e None:\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# ----------  METRICS  ----------------------------------------------------------\n\ndef accuracy_from_logits(logits: torch.Tensor, targets: torch.Tensor) -\u003e float:\n    preds = logits.argmax(dim=1)\n    correct = (preds == targets).float().sum().item()\n    return correct / len(targets)\n\n# ----------  TRAINING WORKER  --------------------------------------------------\n\ndef train_model(cfg: Dict[str, Any], model: nn.Module, train_loader, val_loader, budget: int, writer: SummaryWriter, global_step: int) -\u003e Tuple[float, float]:\n    \"\"\"Train *from scratch* for `budget` epochs and return validation accuracy\n    and approximate FLOPs (we estimate FLOPs = 6 * #params * #samples * epochs).\n    While we could resume from checkpoints, we opt for a stateless worker for\n    clarity.  This does not affect the scheduling logic because budgets are\n    still respected.\n    \"\"\"\n    criterion = nn.CrossEntropyLoss()\n    lr = cfg[\"optim\"].get(\"lr\", 1e-3)\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n\n    params = sum(p.numel() for p in model.parameters())\n    num_samples = len(train_loader.dataset)\n    estimate_flops = 6 * params * num_samples * budget  # heuristic\n\n    model.to(DEVICE)\n    for epoch in range(1, budget + 1):\n        model.train()\n        for X, y in train_loader:\n            X, y = X.to(DEVICE), y.to(DEVICE)\n            optimizer.zero_grad()\n            logits = model(X)\n            loss = criterion(logits, y)\n            loss.backward()\n            optimizer.step()\n        # Optional: early stopping hooks could be inserted here\n    # ----------  validation  -----------\n    model.eval()\n    val_accs = []\n    with torch.no_grad():\n        for X, y in val_loader:\n            X, y = X.to(DEVICE), y.to(DEVICE)\n            logits = model(X)\n            val_accs.append(accuracy_from_logits(logits, y))\n    val_acc = float(np.mean(val_accs))\n\n    # ----------  logging  ---------------\n    writer.add_scalar(\"accuracy/val\", val_acc, global_step)\n    writer.add_scalar(\"resources/params\", params, global_step)\n    writer.add_scalar(\"resources/flops\", estimate_flops, global_step)\n\n    return val_acc, estimate_flops\n\n# ----------  CONFIGURATION  ----------------------------------------------------\n\ndef load_config(path: Path) -\u003e Dict[str, Any]:\n    with open(path) as f:\n        return yaml.safe_load(f)\n\n# ----------  SCHEDULERS  -------------------------------------------------------\nclass BaseScheduler:\n    \"\"\"Abstract base class for asynchronous multi-fidelity schedulers.\"\"\"\n\n    def __init__(self, cfg: Dict[str, Any], writer: SummaryWriter):\n        self.cfg = cfg\n        self.writer = writer\n        self.eta = cfg.get(\"eta\", 3)\n        self.budgets = cfg[BUDGETS_KEY]\n        self.max_total_trials = cfg.get(\"max_total_trials\", 50)\n        self.rungs: List[Dict[int, Dict[str, Any]]] = [dict() for _ in self.budgets]\n        self.trial_info: Dict[int, Dict[str, Any]] = {}\n        self.next_tid: int = 0\n\n        # For resource tracking\n        self.global_step = 0\n\n    # ------  Hooks that subclasses may override  -----------------------------\n    def on_result(self, tid: int, rung_idx: int):\n        pass\n\n    def promotion_decision(self, rung_idx: int) -\u003e List[int]:\n        \"\"\"Return list of trial ids to promote from rung `rung_idx` to next rung.\"\"\"\n        topK = max(1, len(self.rungs[rung_idx]) // self.eta)\n        # Sort by higher accuracy =\u003e better\n        sorted_trials = sorted(self.rungs[rung_idx].items(), key=lambda kv: kv[1][\"score\"], reverse=True)\n        promote = [tid for tid, _ in sorted_trials[:topK]]\n        return promote\n\n    # ------  API  -------------------------------------------------------------\n    def request_trial(self) -\u003e Tuple[int, int]:\n        \"\"\"Get the next (trial_id, budget) to run. If a promotion is scheduled,\n        this will return an existing trial id with a higher budget. Otherwise a\n        new trial is spawned with the minimum budget.\n        \"\"\"\n        # Check promotions from highest to lowest rung (reverse order)\n        for idx in range(len(self.budgets) - 1):\n            rung_idx = len(self.budgets) - 2 - idx\n            promote_ids = self.promotion_decision(rung_idx)\n            for tid in promote_ids:\n                info = self.rungs[rung_idx][tid]\n                if not info.get(\"promoted\", False):\n                    info[\"promoted\"] = True\n                    return tid, self.budgets[rung_idx + 1]\n        # Otherwise, start a new one\n        if self.next_tid \u003e= self.max_total_trials:\n            # Budget exhausted \u2013 return sentinel to stop the optimisation loop\n            return -1, -1\n        tid = self.next_tid\n        self.next_tid += 1\n        return tid, self.budgets[0]\n\n    def report_result(self, tid: int, budget: int, score: float, flops: float) -\u003e None:\n        rung_idx = self.budgets.index(budget)\n        self.rungs[rung_idx][tid] = {\n            \"score\": score,\n            \"flops\": flops,\n            \"budget\": budget,\n            \"promoted\": False,\n        }\n        self.trial_info.setdefault(tid, {\"history\": []})\n        self.trial_info[tid][\"history\"].append((budget, score, flops))\n        self.writer.add_scalar(f\"trials/{tid}/score\", score, self.global_step)\n        self.writer.add_scalar(f\"trials/{tid}/budget\", budget, self.global_step)\n        self.global_step += 1\n        self.on_result(tid, rung_idx)\n\n    # Convenience utilities ---------------------------------------------------\n    def best_overall_score(self) -\u003e float:\n        best = -float(\"inf\")\n        for rung in self.rungs:\n            for d in rung.values():\n                best = max(best, d[\"score\"])\n        return best\n\n\nclass ASHAScheduler(BaseScheduler):\n    pass  # behaviour completely defined in BaseScheduler\n\n\nclass PASHAScheduler(BaseScheduler):\n    \"\"\"PASHA with \u03b5-stability heuristic as described in the original paper.\"\"\"\n\n    def __init__(self, cfg: Dict[str, Any], writer: SummaryWriter):\n        super().__init__(cfg, writer)\n        self.epsilon = cfg.get(\"eps_init\", 0.01)\n        self.window = cfg.get(\"eps_window\", 5)\n        self.rank_histories: List[List[List[int]]] = [[] for _ in self.budgets]\n\n    def on_result(self, tid: int, rung_idx: int):\n        # Record ranking at that rung\n        scores = [v[\"score\"] for v in self.rungs[rung_idx].values()]\n        # skip if \u003c2\n        if len(scores) \u003c 2:\n            return\n        ranking = list(np.argsort(scores)[::-1])  # higher is better\n        self.rank_histories[rung_idx].append(ranking)\n        if len(self.rank_histories[rung_idx]) \u003e self.window:\n            self.rank_histories[rung_idx].pop(0)\n        # Compute epsilon estimate\n        if len(self.rank_histories[rung_idx]) == self.window:\n            # pairwise distance between rankings\n            dists = []\n            for i in range(self.window - 1):\n                dist = np.mean(np.abs(np.array(self.rank_histories[rung_idx][i]) - np.array(self.rank_histories[rung_idx][i + 1])))\n                dists.append(dist)\n            eps_est = float(np.mean(dists))\n            if eps_est \u003c self.epsilon:\n                # Stable \u2013 keep current T_max.\n                pass\n            else:\n                # Not stable \u2013 double max budget by adding a larger rung if possible\n                self._maybe_add_rung()\n\n    def _maybe_add_rung(self):\n        max_budget = self.budgets[-1]\n        new_budget = max_budget * self.eta\n        if new_budget \u003c= self.cfg.get(\"absolute_max_budget\", new_budget):\n            self.budgets.append(new_budget)\n            self.rungs.append(dict())\n            self.rank_histories.append([])\n            self.writer.add_text(\"PASHA/Event\", f\"Doubled T_max to {new_budget}\", self.global_step)\n\n\nclass SAPASHAScheduler(BaseScheduler):\n    \"\"\"Surrogate-Assisted PASHA with Deep Ranking Ensemble (full version).\"\"\"\n\n    def __init__(self, cfg: Dict[str, Any], writer: SummaryWriter, dre_kwargs: Dict[str, Any]):\n        super().__init__(cfg, writer)\n        self.tau = cfg.get(\"tau\", 0.9)\n        self.dre = DREEnsemble(**dre_kwargs)\n\n    def on_result(self, tid: int, rung_idx: int):\n        if rung_idx \u003c len(self.budgets) - 2:\n            return  # we need at least two top rungs full\n        # Top two rungs\n        top_rung = self.rungs[-1]\n        prev_rung = self.rungs[-2]\n        K = len(top_rung) + len(prev_rung)\n        if K \u003c 2:\n            return\n        # Gather training data from *all* evaluations so far\n        X_all, y_all = self._gather_training_data()\n        self.dre.fit(X_all, y_all)\n        # Union of two rungs\n        cfg_ids = list(top_rung.keys()) + list(prev_rung.keys())\n        X_union = self._configs_to_vectors(cfg_ids)\n        ranks = self.dre.sample_rankings(torch.tensor(X_union, dtype=torch.float32), M=256)\n        A = self._pairwise_agreement(ranks)\n        rho = A.mean().item()\n        self.writer.add_scalar(\"rho\", rho, self.global_step)\n        if rho \u003c self.tau:\n            self._double_max_budget()\n\n    # ----------  Helpers  -----------------------------------------------\n    def _gather_training_data(self) -\u003e Tuple[torch.Tensor, torch.Tensor]:\n        vecs, scores = [], []\n        for tid, info in self.trial_info.items():\n            for budget, score, _ in info[\"history\"]:\n                vec = self._config_to_vector(tid, budget)\n                vecs.append(vec)\n                scores.append(score)\n        return torch.tensor(vecs, dtype=torch.float32), torch.tensor(scores, dtype=torch.float32)\n\n    def _config_to_vector(self, tid: int, budget: int) -\u003e List[float]:\n        # Simple representation: [budget_normalised] + random LR + hidden units from trial_info meta\n        budget_norm = budget / self.budgets[-1]\n        meta = self.trial_info[tid].get(\"meta\", {})\n        lr = meta.get(\"lr\", 0.01)\n        hu = meta.get(\"hidden\", 128)\n        return [budget_norm, lr, hu]\n\n    def _configs_to_vectors(self, tids: List[int]) -\u003e List[List[float]]:\n        return [self._config_to_vector(tid, self.trial_info[tid][\"history\"][-1][0]) for tid in tids]\n\n    @staticmethod\n    def _pairwise_agreement(ranks: torch.Tensor) -\u003e torch.Tensor:\n        # ranks: M x K (indices)\n        M, K = ranks.shape\n        A = torch.zeros(K, K)\n        for m in range(M):\n            rank_vec = ranks[m]\n            order = {int(rank_vec[i]): i for i in range(K)}\n            for i in range(K):\n                for j in range(K):\n                    if i == j:\n                        continue\n                    A[i, j] += 1 if order[i] \u003c order[j] else 0\n        A = A / M\n        return A\n\n    def _double_max_budget(self):\n        max_budget = self.budgets[-1]\n        new_budget = max_budget * self.eta\n        abs_max = self.cfg.get(\"absolute_max_budget\", new_budget)\n        if new_budget \u003c= abs_max:\n            self.budgets.append(new_budget)\n            self.rungs.append(dict())\n            self.writer.add_text(\"SA-PASHA/Event\", f\"Doubled T_max to {new_budget}\", self.global_step)\n\n\nclass SAPASHANoDREScheduler(SAPASHAScheduler):\n    \"\"\"Ablation: Uses uniform random surrogate, equivalent to no DRE.\"\"\"\n\n    def __init__(self, cfg: Dict[str, Any], writer: SummaryWriter):\n        super().__init__(cfg, writer, dre_kwargs=dict(ens_size=1, input_dim=3, hidden_dim=8))\n\n    def on_result(self, tid: int, rung_idx: int):\n        # Overwrite surrogate behaviour with random ranks\n        if rung_idx \u003c len(self.budgets) - 2:\n            return\n        K = len(self.rungs[-1]) + len(self.rungs[-2])\n        if K \u003c 2:\n            return\n        rho = random.random()  # Uniform [0,1]\n        self.writer.add_scalar(\"rho\", rho, self.global_step)\n        if rho \u003c self.tau:\n            self._double_max_budget()\n\n\nclass HYBANDScheduler(BaseScheduler):\n    \"\"\"Simplified Hyperband (synchronous) implementation as a comparison.\"\"\"\n\n    def promotion_decision(self, rung_idx: int) -\u003e List[int]:\n        # Hyperband is synchronous \u2013 promote only when rung is complete\n        n_i = self.cfg.get(\"initial_num_configs\", 1)\n        # Calculate expected population per rung as n_i / eta^r\n        expected = int(max(1, n_i / (self.eta ** rung_idx)))\n        if len(self.rungs[rung_idx]) \u003e= expected:\n            return super().promotion_decision(rung_idx)\n        return []\n\n\n# ----------  RANDOM SEARCHER (CONFIG GENERATOR) -------------------------------\n\ndef sample_hyperparams() -\u003e Dict[str, Any]:\n    # This can be replaced by MOBSTER/BO in future experiments\n    return {\n        \"lr\": 10 ** random.uniform(-4, -1),\n        \"hidden\": random.choice([64, 128, 256]),\n    }\n\n\n# ----------  OPTIMISATION LOOP  -----------------------------------------------\n\ndef optimisation_loop(cfg: Dict[str, Any], variation: str, seed: int):\n    set_global_seed(seed)\n\n    now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    logdir = RESULTS_DIR / variation / f\"seed{seed}_{now}\"\n    logdir.mkdir(parents=True, exist_ok=True)\n    writer = SummaryWriter(str(logdir))\n\n    # Data --------------------------------------------------------------------\n    train_loader, val_loader, input_dim, num_classes = get_data_loaders(cfg)\n\n    # Pick scheduler ----------------------------------------------------------\n    if variation == \"ASHA-baseline\":\n        scheduler = ASHAScheduler(cfg, writer)\n    elif variation == \"PASHA-eps\":\n        scheduler = PASHAScheduler(cfg, writer)\n    elif variation == \"SA-PASHA-full\":\n        scheduler = SAPASHAScheduler(cfg, writer, dre_kwargs=dict(ens_size=10, input_dim=3, hidden_dim=32))\n    elif variation == \"SA-PASHA-noDRE\":\n        scheduler = SAPASHANoDREScheduler(cfg, writer)\n    elif variation == \"HYBAND\":\n        scheduler = HYBANDScheduler(cfg, writer)\n    else:\n        raise ValueError(f\"Unknown variation: {variation}\")\n\n    # Main loop ---------------------------------------------------------------\n    pbar = tqdm(total=cfg.get(\"max_total_trials\", 50) * len(cfg[BUDGETS_KEY]))\n    while True:\n        tid, budget = scheduler.request_trial()\n        if tid == -1:\n            break  # optimisation finished\n        # Prepare hyper-parameters for the given trial id\n        if tid not in scheduler.trial_info:\n            hyperparams = sample_hyperparams()\n            scheduler.trial_info.setdefault(tid, {})[\"meta\"] = hyperparams\n        else:\n            hyperparams = scheduler.trial_info[tid][\"meta\"]\n\n        model_cfg = copy.deepcopy(cfg[\"model\"])\n        model_cfg.update(hyperparams)\n        model = build_model(model_cfg, input_dim, num_classes)\n        score, flops = train_model(cfg, model, train_loader, val_loader, budget, writer, scheduler.global_step)\n        scheduler.report_result(tid, budget, score, flops)\n        pbar.update(1)\n\n    pbar.close()\n    # Final summary -----------------------------------------------------------\n    best_score = scheduler.best_overall_score()\n    writer.add_hparams({\"variation\": variation}, {\"best_score\": best_score})\n    writer.flush()\n    writer.close()\n    # Save scheduler state for future reproducibility\n    with open(logdir / \"scheduler_state.json\", \"w\") as f:\n        json.dump({\"trials\": scheduler.trial_info, \"budgets\": scheduler.budgets}, f, indent=2)\n\n# ----------  ENTRY POINT  -----------------------------------------------------\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    group = parser.add_mutually_exclusive_group(required=True)\n    group.add_argument(\"--smoke-test\", action=\"store_true\", help=\"Run quick validation with minimal settings.\")\n    group.add_argument(\"--full-experiment\", action=\"store_true\", help=\"Run full experiment (reads full_experiment.yaml)\")\n    parser.add_argument(\"--variation\", type=str, default=\"ASHA-baseline\", help=\"Variation name (see run_variations list).\")\n    parser.add_argument(\"--seed\", type=int, default=0)\n    return parser.parse_args()\n\n\ndef main():\n    args = parse_args()\n    if args.smoke_test:\n        cfg_path = Path(\"config/smoke_test.yaml\")\n    else:\n        cfg_path = Path(\"config/full_experiment.yaml\")\n    cfg = load_config(cfg_path)\n    optimisation_loop(cfg, args.variation, args.seed)\n\n\nif __name__ == \"__main__\":\n    main()\n"}

Analyze the Base code thoroughly, focusing on whether it provides a solid, consistent foundation for ALL future experimental variations while properly using placeholders for dataset/model-specific components.
Output:
{
    "is_base_code_ready": false,
    "base_code_issue": "Core infrastructure lacks model checkpoint saving/loading: train.py trains models but never saves weights, and there is no mechanism to reload and continue training when a trial is promoted to a higher rung. Base requirements explicitly demand model saving/loading, so criterion 1 (complete core logic) is not fully satisfied. All other criteria appear to be met, but this missing functionality prevents the base code from being considered ready."
}
